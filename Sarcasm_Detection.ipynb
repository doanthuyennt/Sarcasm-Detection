{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE-MvP1hoKE-",
        "colab_type": "text"
      },
      "source": [
        "# Mô tả bài toán:\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyeymCAuoOyU",
        "colab_type": "text"
      },
      "source": [
        "- Con người ta hay ở chỗ là \"miệng nói 1 mà lòng nghĩ 2\", thế mà không chỉ \"nói\" mà còn cả viết nữa, các nhà thơ, nhà văn đã viết lên những bài văn có tính ngụ ý cao, những lời hay nhưng nghĩa châm biếm, đả kích rất hay.\n",
        "- Vì thế các tin tức hiện nay, của Donald Trump hay của bất kì celeb nổi tiếng nào cũng làm các con AI của Facebook hay Google đau đầu vì không biết họ có ý như là họ viết dòng twitter đó hay không ???\n",
        "- Nên có các tập datasets đã được thu thập bởi Kaggle, hay bất kì ai từ 2 nguồn tin cậy cho thứ nhất: tin thật sự,không mỉa mai và hai: tin châm biến mà đến giờ tôi biết là https://www.huffpost.com/ - chuyên tin chính thống và https://www.theonion.com/ - chuyên tin lá cải,châm biếm.\n",
        "- Và lý do không chọn Twitter làm nguồn cho tập dữ liệu: vì nó có cả 2 loại tin và ngay cả con người cũng khó phân biệt ra 2 loại tin này và ta lại mất thời gian đi gán nhãn dữ liệu. Nhưng cũng có thể test headline trên twitter sau khi đã (cho rằng) train xong model.\n",
        "\n",
        "[Sarcasm_Detection_on_Facebook](https://www.researchgate.net/publication/327639471_Sarcasm_Detection_on_Facebook_A_Supervised_Learning_Approach)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJkzU5ZbqNoP",
        "colab_type": "text"
      },
      "source": [
        "- Đỏi ngược quá trình tí xíu: đây là các bước download, train ,đánh giá,finetune mô hình, còn bước crawl,thu nhập dữ liệu sẽ ở gần cuối để chỉ ra: không có dữ liệu crawl được nào được đưa vào mô hình được train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfzQdXr3oMIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c8925a04-8e34-4db7-de4e-71aa265e6f48"
      },
      "source": [
        "!wget \"https://storage.googleapis.com/kaggle-data-sets/30764%2F533474%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1592881274&Signature=GrZQXFVKopyK4MVIuh20xJ0lMzISDvCN3EHWv1AE0Qk53CTBk8LCdwfgQL1fnbh7DdO%2B10oKQWl%2FLlQq8kZ3mVQgrHY6DzUpWhUUiLg6nrLkQ%2Fd7QQmKf8u3Sd2zNGAf%2BknymMNeL7%2FXTXYYtQTWuMXw5BjTYdJe11TbefnyvyZBlzmUSb7MnQ9fLiQJEEXaz8LyRjKo8nm4dkYOzYwUFXu0MSFC6oB9lpb89i%2FtNWAMKcgszSzzoIDZgYCdHYE4apfr8fRsxNiZQZhcHKdHJmpkx17qQuue%2FhbqKdfSE4QC6dtH9SutB1JbdORGYUQ%2FHMTmcl%2FNV9lEhlPaH79PPQ%3D%3D\" -O \"headlines.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-23 14:50:51--  https://storage.googleapis.com/kaggle-data-sets/30764%2F533474%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1592881274&Signature=GrZQXFVKopyK4MVIuh20xJ0lMzISDvCN3EHWv1AE0Qk53CTBk8LCdwfgQL1fnbh7DdO%2B10oKQWl%2FLlQq8kZ3mVQgrHY6DzUpWhUUiLg6nrLkQ%2Fd7QQmKf8u3Sd2zNGAf%2BknymMNeL7%2FXTXYYtQTWuMXw5BjTYdJe11TbefnyvyZBlzmUSb7MnQ9fLiQJEEXaz8LyRjKo8nm4dkYOzYwUFXu0MSFC6oB9lpb89i%2FtNWAMKcgszSzzoIDZgYCdHYE4apfr8fRsxNiZQZhcHKdHJmpkx17qQuue%2FhbqKdfSE4QC6dtH9SutB1JbdORGYUQ%2FHMTmcl%2FNV9lEhlPaH79PPQ%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.31.128, 2607:f8b0:400c:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 400 Bad Request\n",
            "2020-06-23 14:50:52 ERROR 400: Bad Request.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKRp1jjMr-IB",
        "colab_type": "text"
      },
      "source": [
        "File rất nhẹ, không gì lo cho việc đường truyền hay nặng google cả, đâu phải máy của mình."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwR3_mjTrvaX",
        "colab_type": "text"
      },
      "source": [
        "Ở đây mình dùng luôn unzip trên linux, không cần cài đặt gì cả!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk9scKWFrM8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "11112c4f-9633-4580-899f-fbbfcfda3855"
      },
      "source": [
        "!unzip \"/content/headlines.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/headlines.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/headlines.zip or\n",
            "        /content/headlines.zip.zip, and cannot find /content/headlines.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFekaC8asJcT",
        "colab_type": "text"
      },
      "source": [
        "Để đọc file json, và pandas có hỗ trợ việc đọc này."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f-dLR5Ht8ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-3_GcB2uc7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8398a9b6-47f6-4218-aa10-00ec3a0db2e1"
      },
      "source": [
        "data_first = pd.read_json(\"Sarcasm_Headlines_Dataset.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7ccef9964cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sarcasm_Headlines_Dataset.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1089\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m             )\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6q7N3V9ul4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f3d1db92-1b4f-49e7-c178-0def45ea162f"
      },
      "source": [
        "# Không cho vậy thì ta đọc theo dòng !!\n",
        "data_first = pd.read_json(\"Sarcasm_Headlines_Dataset.json\",lines=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-375b71d13256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Không cho vậy thì ta đọc theo dòng !!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sarcasm_Headlines_Dataset.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1089\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m             )\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc6uj3Vluyla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "ac8af638-a655-49ba-f7c9-051254fd8330"
      },
      "source": [
        "data_first.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d46ddabfad5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_first' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q5fiMJzu4UF",
        "colab_type": "text"
      },
      "source": [
        "Tương tự:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnFFUQnJuz79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thêm mỗi _v2\n",
        "data_second = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\",lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o962ivB4u-kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_second.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMhHp_YbwGcn",
        "colab_type": "text"
      },
      "source": [
        "## Tìm hiểu dữ liệu:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmir91nnvNC9",
        "colab_type": "text"
      },
      "source": [
        "Kiểm tra dữ liệu: có missing, skew hay bla bla gì không."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrkLShSuvdwk",
        "colab_type": "text"
      },
      "source": [
        "pandas cũng hỗ trợ nốt trong việc tìm missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttKPahRavCAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hàm isna trả về False nếu ko là na:mất thông tin, True : nếu có mất thông tin\n",
        "# Và False được xem là giá trị 0 còn True được xem là giá trị 1: nên ta tổng theo từng feature/cột\n",
        "data_first.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpZzprrivMYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_first.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYq53Q7nv8sn",
        "colab_type": "text"
      },
      "source": [
        "Tương tự trên data_second"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBgOanATvo_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_second.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXP6Q_IEwQkF",
        "colab_type": "text"
      },
      "source": [
        "pandas hỗ trợ lấy cả index bằng số lẫn nên cột.\n",
        "- iloc : hỗ trợ lấy bằng số/index.\n",
        "- loc : hỗ trợ lấy bằng tên cột."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E-2VxKkwBOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_first.loc[:,\"is_sarcastic\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ4f7XnNw7Gg",
        "colab_type": "text"
      },
      "source": [
        "Hàm value count : đếm giá trị đặc biệt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8rZM-3pwPYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_first.loc[:,\"is_sarcastic\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tti34SoBwg_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_second.loc[:,\"is_sarcastic\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUPT__owyGlw",
        "colab_type": "text"
      },
      "source": [
        "seaborn là một thư viện hỗ trợ việc plot dữ liệu như matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhKWeYCDx_Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_style(\"dark\")\n",
        "sns.countplot(data_second.loc[:,\"is_sarcastic\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC2UGfmrxJ0w",
        "colab_type": "text"
      },
      "source": [
        "Dữ liệu hơi hơi lệch về \"không phải châm biếm\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HkdAVVsxTqu",
        "colab_type": "text"
      },
      "source": [
        "Trong đây ta không cần đường dẫn vì không ai trong đây rảnh mà mở lên đọc cả :))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUBeHm1exIxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_first.drop(columns= 'article_link' , inplace = True)\n",
        "data_second.drop(columns= 'article_link', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykCqILPeyc6s",
        "colab_type": "text"
      },
      "source": [
        "Thư viện nltk : Natural Language Toolkit hỗ trợ cho ta việc xử lý ngôn ngữ tự nhiên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU77NqppTkV9",
        "colab_type": "text"
      },
      "source": [
        "## Xử lý ngôn ngữ tự nhiên:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgDUbM7txyjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import re,string,unicodedata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-adaG8VysEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayw8Hv-OzHgA",
        "colab_type": "text"
      },
      "source": [
        "Để sửa lỗi này: ta thực hiện y hệt những gì thư viện quăng lại lỗi!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mRyunAEy6de",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URmpMElizDJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5ExT0GGzTrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfPqx7f0zj9H",
        "colab_type": "text"
      },
      "source": [
        "Thế thì tại sao cần qua bước stopword này vì các từ như so, or , now , no, have(had having) gì gì đó chả có đóng góp gì nhiều trong câu, và trong tiếng Anh và cụ thể là đang trên bài toán phát hiện châm biếm này bằng tập dữ liệu tiếng anh, ta có thể loại đi các từ này mà chắc chắn rằng , không làm ảnh hưởng đến model.\n",
        "\n",
        "- Link tham khảo stopword Tiếng Việt:\n",
        "[Stopword cho Tiếng Việt](https://github.com/NguyenVanHieuBlog/vietnamese-stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnFLkknt1fZC",
        "colab_type": "text"
      },
      "source": [
        "Các helper function cho việc clean dữ liệu. Sau này đóng gói, tạo file .py làm lại cho nhanh cũng được."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYH_kYGa1_a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_LfS_S5zfgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Ddek2q12Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply function on review column\n",
        "data_first['headline']=data_first['headline'].apply(denoise_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISdpkt1N16o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_first"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KslFeKu7CnQL",
        "colab_type": "text"
      },
      "source": [
        "WORDCLOUD cho các từ xuất hiện trong headline có tính châm biếm : is_sarcastic = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBqzEzy5Bqb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (20,20)) # Text that is Sarcastic\n",
        "wc = WordCloud(max_words = 2000 , width = 1400 , height = 800).generate(\" \".join(data_first[data_first.is_sarcastic == 1].headline))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRzk7eMtCWRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (20,20)) # Text that is Sarcastic\n",
        "wc = WordCloud(max_words = 2000 , width = 1400 , height = 800).generate(\" \".join(data_first[data_first.is_sarcastic == 0].headline))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luki3a62F2Bl",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING WORD2VEC MODEL:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkOflTbWXpUS",
        "colab_type": "text"
      },
      "source": [
        "## Giới thiệu về WORD2VEC:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-a8T5boXto-",
        "colab_type": "text"
      },
      "source": [
        "Word2vec is a two-layer neural net that processes text by “vectorizing” words. Its input is a text corpus and its output is a set of vectors: feature vectors that represent words in that corpus. While Word2vec is not a deep neural network, it turns text into a numerical form that deep neural networks can understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BvJoODOAOCq",
        "colab_type": "text"
      },
      "source": [
        "**Word2vec** là sự kết hợp giữa 2 mạng nơron **Skip-Gram** và **CBOW** - kết quả là  **Word2vec** cũng là một mạng nơron:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTP06CCXAasH",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://thorpham.github.io/assets/images/word2vec1.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9T9vYDGGhWi",
        "colab_type": "text"
      },
      "source": [
        "**CBOW** Model: Nôm na là phương pháp đem chỉ 1 từ làm input và đoán ngữ cảnh của từ đó - hay nói cách khác là có thể các từ nào xuất hiện kèm với từ đó.\n",
        "- Ví dụ : cho cụm từ \"Have a great day\".\n",
        "Ta cần dự đoán từ nào sẽ xuất hiện nếu cho qua một model được mà ta thiết kế chỉ một từ duy nhất **great**; Đầu ra ta muốn ở đây là từ **day** vì **great day** sẽ có ý nghĩa hơn **great a** hay **great Have**.\n",
        "- Cụ thể hơn là ta biến đổi one-hot-encoding/one-hot-vector fit trên câu \"Have a great day\" rồi tương ứng được vector của **great** sẽ là [0 0 1 0] và đưa qua mạng nơron gì gì đó để nó học lại đầu ra qua softmax và cuối cùng là dự đoán bằng softmax sao cho mạng được huấn luyện sẽ ngày cần giá trị [0 0 0 1] nhất. đại khái là thế."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZr6A4dQ8gf",
        "colab_type": "text"
      },
      "source": [
        "Còn model **Skip-Gram** là model ngược lại so với CBOW:\n",
        "![alt text](https://miro.medium.com/max/1400/0*Ta3qx5CQsrJloyCA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_KFbzdNXVfj",
        "colab_type": "text"
      },
      "source": [
        "Xử lý dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rk2ic0NC7VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for i in data_first.headline.values:\n",
        "    l = []\n",
        "    for j in i.split():\n",
        "        l.extend(i.split())\n",
        "        break\n",
        "    words.append(l)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd3xoIA9Xdnm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7D-0OKtDbh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "#Dimension of vectors we are generating\n",
        "EMBEDDING_DIM = 200\n",
        "MAXLEN = 150\n",
        "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
        "w2v_model = gensim.models.Word2Vec(sentences = words , size=EMBEDDING_DIM , window = 5 , min_count = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLY7skJjDlXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import text, sequence\n",
        "tokenizer = text.Tokenizer(num_words=35000)\n",
        "tokenizer.fit_on_texts(words)\n",
        "tokenized_train = tokenizer.texts_to_sequences(words)\n",
        "x = sequence.pad_sequences(tokenized_train, maxlen = MAXLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajvoVHB9D0FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
        "# Thus our vocab size inceeases by 1\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTxZ93CtD-Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create weight matrix from word2vec gensim model\n",
        "def get_weight_matrix(model, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = model[word]\n",
        "    return weight_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjGo5X_SEAJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXKnVfcqECGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_vectors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxPJ3_YlEGal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "\n",
        "#Defining Neural Network\n",
        "model = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=20, trainable=True))\n",
        "#LSTM \n",
        "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.3 , dropout = 0.3)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwHowB0_Eu32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJwpsZCVE7AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, data_first.is_sarcastic , test_size = 0.3 , random_state = 0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDFDNjfeFHJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "history = model.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeBodTIPFqvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = [i for i in range(EPOCHS)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\n",
        "ax[0].set_title('Training & Testing Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\n",
        "ax[1].plot(epochs , val_loss , 'ro-' , label = 'Testing Loss')\n",
        "ax[1].set_title('Training & Testing Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iUqSRqEHRGa",
        "colab_type": "text"
      },
      "source": [
        "Model có vấn đề: acc quá cáo so với val_acc, và val_acc còn không tăng lên cao được là do model đã ghi nhớ chứ không còn học được gì nữa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDCXXSmIVik",
        "colab_type": "text"
      },
      "source": [
        "Thay đổi với model trước : tăng số lượng neuron bị drop cho cả recurrent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN6iVnoOTGft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEXlV_vIHOrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining Neural Network\n",
        "model_2 = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model_2.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=20, trainable=True))\n",
        "#LSTM \n",
        "model_2.add(Bidirectional(LSTM(units=128,return_sequences=True)))\n",
        "model_2.add(Bidirectional(LSTM(units=64 , recurrent_dropout = 0.4 , dropout = 0.5)))\n",
        "model_2.add(Dense(32,activation='relu'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "model_2.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEebNmv3Qgt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tăng batch_size\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "history = model_2.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLc88M1fJQkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = [i for i in range(EPOCHS)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\n",
        "ax[0].set_title('Training & Testing Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\n",
        "ax[1].plot(epochs , val_loss , 'ro-' , label = 'Testing Loss')\n",
        "ax[1].set_title('Training & Testing Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwRwcT_lJUKo",
        "colab_type": "text"
      },
      "source": [
        "Nhận xét: cũng không khá hơn gì so với model đầu.Vậy thử predict kết quả như thế nào."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSv5ry6oH7CI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(x_test)\n",
        "print(y_pred[:5],y_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wb0tlb2JuB5",
        "colab_type": "text"
      },
      "source": [
        "Ouput củ chuối, print lại:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xff4f2mqJmTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred[:5],y_test[:5].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuY_mQGcJpvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred[:5].reshape(-1))\n",
        "print(y_test[:5].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baI5ArG3J3-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO-2OCfVKFIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(y_pred,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xROWhUBKf_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.4)\n",
        "col_ind_names = ['Not Sarcastic','Sarcastic']\n",
        "cm = pd.DataFrame(confusion_matrix(y_pred,y_test) , index = col_ind_names , columns = col_ind_names)\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , \n",
        "            annot = True, fmt='' , xticklabels = col_ind_names , yticklabels =col_ind_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zUh62OGL0cX",
        "colab_type": "text"
      },
      "source": [
        "Cũng chả hiểu gì!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q39ao-wSLRZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classification_report(y_test, y_pred, target_names=col_ind_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WDnAZZCMOI6",
        "colab_type": "text"
      },
      "source": [
        "Nó xuất ra kiểu kiểu khó nhìn trên vì nó là ... không biết chỉ biết nó là kiểu chuỗi hoặc dict,nhưng lại có \\n bên ta đưa vào print() cho nó xử lý xuống dòng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMdsstCJMEOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=col_ind_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wxSlhcZWor-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from keras.preprocessing import text, sequence\n",
        "#Dimension of vectors we are generating\n",
        "EMBEDDING_DIM = 200\n",
        "\n",
        "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
        "w2v_model = gensim.models.Word2Vec(sentences = words , size=EMBEDDING_DIM , window = 5 , min_count = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iN0NM9AYvB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 100\n",
        "tokenizer = text.Tokenizer(num_words=35000)\n",
        "tokenizer.fit_on_texts(words)\n",
        "tokenized_train = tokenizer.texts_to_sequences(words)\n",
        "x = sequence.pad_sequences(tokenized_train, maxlen = MAXLEN)\n",
        "\n",
        "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrjlCCSfMKs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining Neural Network\n",
        "model_3 = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model_3.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=MAXLEN, trainable=True))\n",
        "#LSTM \n",
        "model_3.add(Bidirectional(LSTM(units=128,recurrent_dropout = 0.4 , dropout = 0.5,return_sequences=True)))\n",
        "model_3.add(Bidirectional(LSTM(units=64 , recurrent_dropout = 0.4 , dropout = 0.5)))\n",
        "model_3.add(Dense(64,activation='relu'))\n",
        "model_3.add(Dense(1, activation='sigmoid'))\n",
        "model_3.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnhZdp4MUmkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch_size = 64 \n",
        "# Sau khi đã tăng số chiều của x từ 20 lên 100\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, data_first.is_sarcastic , test_size = 0.3 , random_state = 0) \n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "history = model_3.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gRr4-a9Yx9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 100\n",
        "tokenizer = text.Tokenizer(num_words=35000)\n",
        "tokenizer.fit_on_texts(words)\n",
        "# tokenized_train = tokenizer.texts_to_sequences(words)\n",
        "# x = sequence.pad_sequences(tokenized_train, maxlen = MAXLEN)\n",
        "\n",
        "# #Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "# embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AszK81ZBgXN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "5281c33b-3825-4b11-97df-e2e5ce168e76"
      },
      "source": [
        "data_second"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28614</th>\n",
              "      <td>1</td>\n",
              "      <td>jews to celebrate rosh hashasha or something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28615</th>\n",
              "      <td>1</td>\n",
              "      <td>internal affairs investigator disappointed con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28616</th>\n",
              "      <td>0</td>\n",
              "      <td>the most beautiful acceptance speech this week...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28617</th>\n",
              "      <td>1</td>\n",
              "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28618</th>\n",
              "      <td>1</td>\n",
              "      <td>dad clarifies this not a food stop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28619 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       is_sarcastic                                           headline\n",
              "0                 1  thirtysomething scientists unveil doomsday clo...\n",
              "1                 0  dem rep. totally nails why congress is falling...\n",
              "2                 0  eat your veggies: 9 deliciously different recipes\n",
              "3                 1  inclement weather prevents liar from getting t...\n",
              "4                 1  mother comes pretty close to using word 'strea...\n",
              "...             ...                                                ...\n",
              "28614             1       jews to celebrate rosh hashasha or something\n",
              "28615             1  internal affairs investigator disappointed con...\n",
              "28616             0  the most beautiful acceptance speech this week...\n",
              "28617             1  mars probe destroyed by orbiting spielberg-gat...\n",
              "28618             1                 dad clarifies this not a food stop\n",
              "\n",
              "[28619 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqfhqd6YgrdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply function on review column\n",
        "data_second['headline']=data_second['headline'].apply(denoise_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdE-fmY2gTEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words2 = []\n",
        "for i in data_second.headline.values:\n",
        "    l = []\n",
        "    for j in i.split():\n",
        "        l.extend(i.split())\n",
        "        break\n",
        "    words2.append(l)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCAUigh4gv8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_train_2 = tokenizer.texts_to_sequences(words2)\n",
        "x_2 = sequence.pad_sequences(tokenized_train_2, maxlen = MAXLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyYeN53hhEQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_2 = data_second.is_sarcastic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcQz14b2hKYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_3.predict_classes(x_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fazcw5DhXgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "e6e9ee81-b6d8-48f5-cd9e-8d151c7a5466"
      },
      "source": [
        "print(classification_report(y_2, y_pred, target_names=col_ind_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Sarcastic       0.91      0.94      0.93     14985\n",
            "    Sarcastic       0.93      0.90      0.92     13634\n",
            "\n",
            "     accuracy                           0.92     28619\n",
            "    macro avg       0.92      0.92      0.92     28619\n",
            " weighted avg       0.92      0.92      0.92     28619\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQM2UurqiDbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "221b8961-cb13-4793-e525-ab81e8f725bb"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.4)\n",
        "col_ind_names = ['Not Sarcastic','Sarcastic']\n",
        "cm = pd.DataFrame(confusion_matrix(y_pred,y_2) , index = col_ind_names , columns = col_ind_names)\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , \n",
        "            annot = True, fmt='' , xticklabels = col_ind_names , yticklabels =col_ind_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd468bec358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJJCAYAAABoJXlRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdfXzN9f/H8ecuzNiluZiLXLRNrprZ0BDGULmqqFCEULGQCilS3y+plEbNJKZE8o2kzEV9S2340gUiRbLRImYutmM228x+f/jt1OlsHPrsg+Nxv93O7eZ8Pq/zOe/P6Vvfl+f7fd7HpaioqEgAAAD4x1yv9AAAAACcBY0VAACAQWisAAAADEJjBQAAYBAaKwAAAIPQWAEAABiExgoAAJjut99+0+TJk3XXXXepcePG6tGjxwXrd+3apUaNGik8PNzuXEFBgWbMmKG2bdsqLCxMAwYM0O7du+3qMjIyNGbMGDVv3lwtWrTQ2LFjdeLECbu6nTt36v7771fTpk3Vrl07vfHGGyosLHTovmisAACA6X799VclJSWpbt26Cg4OvmDtuXPn9MILLyggIKDE8y+99JLef/99jR49WvHx8SpXrpwGDx6s9PR0a83Zs2c1bNgw7d27V6+88oqmTp2q7du3KyYmRn/d0vP333/X4MGD5efnp7lz52r48OFKSEhQbGysQ/fl7lAVAACAgaKjo9W5c2dJ0oQJE7Rr165Saz/88EOdOnVK99xzjxYtWmRzLj09XUuXLtXEiRPVp08fSVJYWJg6deqkhQsXavz48ZKkzz//XHv27FFiYqLq168vSapWrZruv/9+JScnKyoqSpI0f/58+fr66o033pCHh4dat26tU6dOafbs2Ro2bJj8/f0veF9XvLFycXG50kMAAMA0Zv/gSYXwkaa9V+72OIdrXV0dmzQ7ceKEYmNj9eqrr2rHjh125zdu3KjCwkJ169bNeszb21sdO3ZUcnKytbFKSkrSTTfdZG2qJCkiIkK1atVSUlKStbFKTk5W586d5eHhYa3r0aOHYmNjtWXLFt1xxx0XHO8Vb6wkybPZY1d6CMB15cwPsyVJWbmOrRkAYAy/Cm5XegjXnNdee00RERFq3759iY1VSkqKqlSpokqVKtkcDwkJUWJios6dOydXV1elpKQoJCTE7vUhISFKTU2VJOXk5OiPP/6wm5q84YYbVKFCBWvdhVwVjRUAACgjLuYtp7ZYLLJYLHbHfX195evre8nX2759u1avXq3ExMQLvqePj4/dcT8/PxUUFCgnJ0fe3t6l1vn6+iolJUWSdOrUKeuxkuqysrIuOmYaKwAAYIiFCxcqLs5+OnDkyJEaNWrUJV2rsLBQ//rXvzR48GDVrl3bqCGWORorAACcmYlrmQcNGqRevXrZHb+ctOrDDz9URkaGHnjgAWsKlpeXJ+l8SuXh4SFPT0/5+vpak6a/ysrKUrly5VSxYkXrGEqqs1gs8vPzkyRrolVS6vbXuguhsQIAAIa43Cm/kqSmpurYsWNq37693bmWLVtq4MCBmjhxooKDg3X8+HFlZmbafGMvJSVF9erVsy6SDw4OLnFvq3379qlDhw6SpIoVK6pmzZrWqcFihw4dUm5uroKCgi46bvaxAgAAV50BAwbovffes3n06tVL5cuX13vvvacBAwZIktq2bStXV1etXbvW+trTp09r/fr1Nk1ZVFSU9u7da9M0/fDDDzp06JD1G4GS1L59e3355ZfKz8+3Hlu9erV164WLIbECAMCZmbh4/VLk5uYqKSlJ0vlEKDs7W+vWrZMkhYaGqm7duqpbt67Na7799lu5ubkpMjLSeiwwMFD9+vXTa6+9Jnd3d9WsWVMLFiyQdH5qsthtt92mBg0aaPTo0XryySdVWFio6dOnKzw83KYBGzZsmFatWqUxY8bowQcfVGpqquLj4zVo0CCmAgEAwNXp+PHjevzxx22OFT9/6aWX1Lt3b4ev9cwzz6hixYqaOXOmTp06pdDQUL3zzjsKDAy01ri7u2v+/Pl68cUXNW7cOLm4uKhDhw6aOHGizZ6atWvX1rvvvqtp06bpkUcekZ+fnx566CGNHOnYfmAuRWbvVPb3Abi4sI8VYDL2sQKuDL8KbuZvENrySdPeK/e71017r6vV1ZkPAgAAXIOYCgQAwJldpWusnBWfNgAAgEFIrAAAcGYmbhAKEisAAADDkFgBAODMWGNlKj5tAAAAg5BYAQDgzFhjZSoSKwAAAIOQWAEA4MxYY2UqPm0AAACDkFgBAODMWGNlKhIrAAAAg9BYAQAAGISpQAAAnBmL103Fpw0AAGAQEisAAJwZi9dNRWIFAABgEBIrAACcGWusTMWnDQAAYBASKwAAnBmJlan4tAEAAAxCYgUAgDNz5VuBZiKxAgAAMAiJFQAAzow1Vqbi0wYAADAIiRUAAM6MnddNRWIFAABgEBIrAACcGWusTMWnDQAAYBAaKwAAAIMwFQgAgDNj8bqpSKwAAAAMQmIFAIAzY/G6qfi0AQAADEJiBQCAM2ONlalIrAAAAAxCYgUAgDNjjZWp+LQBAAAMQmIFAIAzY42VqUisAAAADEJiBQCAM2ONlan4tAEAAAxCYgUAgDNjjZWpSKwAAAAMQmIFAIAzY42Vqfi0AQAADEJjBQAAYBCmAgEAcGZMBZqKTxsAAMAgJFYAADgztlswFYkVAACAQUisAABwZqyxMhWfNgAAgEFIrAAAcGassTIViRUAAIBBSKwAAHBmrLEyFZ82AACAQUisAABwZqyxMhWJFQAAgEFIrAAAcGIuJFamIrECAAAwCIkVAABOjMTKXCRWAAAABqGxAgAAMAhTgQAAODNmAk1FYgUAAGAQEisAAJwYi9fNRWIFAABgEBIrAACcGImVuUisAACA6X777TdNnjxZd911lxo3bqwePXrYnC8sLNS8efM0YMAAtWrVSi1btlT//v21efPmEq+XkJCg6OhoNW3aVL179y6xLjs7W5MnT1ZkZKTCw8M1fPhwHTx40K7uwIEDGjp0qMLDw9WqVStNmTJFubm5Dt0XjRUAAE7MxcXFtMel+PXXX5WUlKS6desqODjY7vyZM2c0d+5cNWzYUC+99JJef/11BQYG6qGHHtJXX31lU5uQkKDY2Fj1799fc+fOVb169fTII49oz549NnVPPfWU1q9fr+eee06xsbE6evSoBg8ebNM0WSwWDRw4UKdPn9asWbM0YcIEJSYm6tlnn3XovpgKBAAApouOjlbnzp0lSRMmTNCuXbtsznt6eurLL7+Un5+f9Vjbtm114MABLViwQB07dpQk5efna86cORo4cKCGDh0qSbrlllvUs2dPzZkzR7NmzZIk7dixQ19//bXefvttRUVFSZJuuukmdenSRStWrFD//v0lSUuXLpXFYtHKlSsVEBAgSXJzc9PYsWMVExOj+vXrX/C+SKwAAHBiV2ti5ep64RbEzc3NpqkqvpeGDRvq6NGj1mPbtm3TqVOn1L17d5vXdu3aVcnJySoqKpIkJSUlycfHR+3atbPW1axZUxEREUpOTrYeS05OVqtWraxNlSTdfvvt8vDwsKkrDYkVAAAwhMVikcVisTvu6+srX1/ff3z9c+fOafv27TZThykpKZJkN50YEhKinJwcpaenq3r16kpJSVFQUJBdQxcSEqKNGzfaXO+ee+6xqfHw8FCdOnWUmpp60THSWAEA4MxM/FLgwoULFRcXZ3d85MiRGjVq1D++/qJFi7R//35NmTLFesxiscjDw0Oenp42tcVpV2ZmpqpXry6LxSIfHx+7a/r6+iorK8vmeiU1gX+vKw2NFQAAMMSgQYPUq1cvu+NGpFXffvutXn31VQ0ZMkQtWrT4x9crKzRWAAA4MTP3sTJqyu/v9uzZo5iYGHXu3Fnjxo2ze8/8/Hzl5eWpfPny1uPF6ZK/v7+17vDhw3bXtlgsNmu5fH19S5zOtFgsCgoKuuhYWbwOAACuWmlpaRo2bJgaN26s6dOn2zWKxWuritdaFUtJSZGXl5cCAwOtdfv377cuZi+2b98+m4YpODjY7lr5+flKS0ujsQIA4Hp3tX4r0BEZGRkaMmSIqlSpovj4eHl4eNjVREREyMfHR2vWrLEeKyws1Nq1a9WuXTvruKKiomSxWLRhwwZr3eHDh7Vt2za1b9/eeqx9+/basmWLTp48aT323//+V/n5+dZtGi6EqUAAAGC63NxcJSUlSZIOHTqk7OxsrVu3TpIUGhqqypUra9iwYTp+/LgmTJigffv22by+WbNmks5/Y2/EiBGKjY1VQECAGjdurGXLliktLU0zZsyw1oeFhalDhw6aOHGiJkyYIG9vb82aNUs1atRQ7969rXX9+vXT4sWLFRMTo5iYGB0/flwvv/yyunXrppCQkIvel0vR3zMxk7m4uMiz2WNXcgjAdefMD7MlSVm5hVd4JMD1xa+Cm91UVFmrNOB9097r5OL+DtcePHhQnTp1KvHcSy+9pFtuuaXU85L0yy+/2DxPSEjQ4sWLdezYMdWvX1/jxo1T69atbWqys7M1ffp0rVu3Tvn5+YqMjNSkSZNUu3Ztm7r9+/dr6tSp2rp1q8qXL6/u3btr3LhxqlChwkXvi8YKuA7RWAFXxpVorAIeXGLae51Y9IBp73W1Yo0VAACAQVhjBQCAEzNzuwWQWAEAABiGxAoAAGdGYGUqEisAAACDkFgBAODEWGNlLhIrAAAAg5BYAQDgxEiszEViBQAAYBASKwAAnBiJlblIrAAAAAxCYgUAgDMjsDIViRUAAIBBSKwAAHBirLEyF4kVAACAQUisAABwYiRW5iKxAgAAMAiNFQAAgEGYCgQAwIkxFWguEisAAACDkFgBAODESKzMRWIFAABgEBIrAACcGYGVqUisAAAADEJiBQCAE2ONlblIrAAAAAxCYgUAgBMjsTIXiRUAAIBBSKwAAHBiJFbmIrECAAAwCIkVAADOjMDKVCRWAAAABiGxAgDAibHGylwkVgAAAAahsQIAADAIU4FOzKuCh54Y1FnNm9RV8yZ1VLWSj5574xO99s5/L/i6xDkj1alVQ81bvlGjX1xqd37gXa00ZmAn3Virig6lZ+qt/yQpbsnXJV4rquVNGj/0NjVvXFdubq7al3ZUcUu+1vurvrHWVPT00OSY7urdOVzVKvvo4JFMvfPxJsW+96XOnSv6B58AcPXIyTmtRe8u0M8//aiff9qlzJMn9djoJzV46MM2df9ZslhffL5Ovx3Yr+zsU6patZqat4zUsEdjVLNWLZvalmGNSnyvkq77V1P/9Zw+WbFcrdq01Ztz5v3zm8NVjalAc9FYObHK/t6a+Gg3HTxyUjv2HFTn1iX/R/iv7ooOU2TTG0s9P/SeWxU36X6t/PIHvbF4vW4ND9Gr4+5VxQrlNT3hM5vaB+9spbeef0BfbvlFL8xepYKzhapft5pqV69krXF1ddEns2MUGXqj5n+0UT+nHFabZkGa+vjduqF6gJ54+cPL/wCAq0jmyUzNnxuvaoHV1aBBI32z5X8l1u3Z/bPq1K2rqI6d5Ovrq0OHDmrliuVKTlqvJR+uVLXAQJv6Fre0Us+7etkca9Cw9H/Xf/5plxI/Xany5cv/85sCYIfGyokdOWZR0G0TdTgjS3VqBOiXNf++YH15D3e9/GQvzXj3v3o+pofdec/y5fTCYz312aafdP/Y+ZKkdz/eLDdXFz099HYlfLRRxzNPS5Lq1AjQzAl9NGdpksa++lGp73lXdJjaRoRo9LSlmrdsoyRp/vKNOnYyW4890EHzl2/UT/v+uNyPALhqVKlaVWv+m6Sq1arpj0OHdFe3ziXWPT9lmt2xDtGdNfD+e5X46cca8vBwm3N16tRVtx53OjSGoqIivfbKi+re40599+2WS78JXJNIrMzFGisnll9wVoczshyuf3JwZ7m6umrme1+WeD6qZX1VqeRtbYCKzf1wgypW8FDXdjdbjz18X1u5ubno33NWS5K8K5b8t+Nbw4MlSf9Z+73N8aVrv5erq6vuvS3C4fEDVzMPDw9VrVbtsl5bo0ZNSdKpU6dKPJ+Xl6czZ85c9DprEj9R6r5fNWLUmMsaB4CLc6ixWrNmjebPn1/iuYSEBK1du9bQQcF8tatX0tjBt2nSrE90Jq+gxJqwBrUlSdt+TrM5vu3nNBUWnlOzhjdYj3WMbKhfDqTrjrZN9OvaKcrYNEN/JE3XlNF3ytX1z789eXiU07lz53Qm76zNNXPO5EuSIhrXMeT+gGtN5smTOn78mH76caf+9dwzkqTIVm3s6tYkfqp2keFqFxmu++7urjWrPinxeqdPn9abM2do8NBHVaVK1TIdO64uLi4upj3g4FTg22+/rd69e5d4ztPTU/PmzVPXrl0NHRjM9fKTvbTjl9+17LOtpdbUqOIrSXYpWMHZQh3POq0aVf2sx0JqV1XhuXOa+8IAvb7wC+385aC6R4Vq7EO3ydOjnMa9dn568NcD6XJ1dVXrZkFK+m6v9fXtmodIkmpW8zfsHoFrxdmzZ9Wlw59NlJ+/v8Y+PVGt2txqU9e0Wbg633aHata6QceOHtWy/yzR85Mm6NSpU+r7wACb2vlz41W+vKceeHCQKfcAXK8caqwOHDig+vXrl3guODhY+/fvN3RQMFf7FvV1d6dmav/gaxes8/Qsp/yCsyWey8srkGd5D+tz74rl5ebmqkmzVmrGu19Ikj5Zv0O+Xp56pE87vTx/nY5nntbSNd/pmUe6as7kBzTm5Q+1J/WwWocF6/mYniooKFSF8uWMu1HgGuHm5qa4uQk6W1Cg1NQUrV29Srm5uXZ1CQuX2Dy/s1dvPdjvXs2ZPUt33t1bFSpWlCT9dmC/lr6/SC++8po8PDzsrgMnR5BkKoemAsuXL6/jx4+XeC4jI0Pu7qyBv1a5ublqxvj7tGT1d9r6tym+vztzpkAe5dxLjHvLly+nM3n51ue5/z+d+OE62wRs6drv5VHOXS1uritJyjiZrXtGvyVJ+iQuRr+smaI5zz+gF+eu0clTOTqVc/F1I4CzcXFxUWSrNrq1XZQeHDREL78aq/lzZ+vDD96/4OvKlfNQn379dTo7Wz//tMt6fMb0l9S0WTNFd76trIcOXPccaqxatmypuXPnKicnx+Z4Tk6O5s2bp1tuuaVMBoey17/HLbqpXjUlfLRRdWoEWB+S5FOxvOrUCFAFz/Op0eFjFklS9f+fEixWzt1Nlf28bKYIi/+cftx2se3R4+evUcmnovXY5h2panLnv9SyzzR1euh13dhlot75+H+q7Oelfb8dNfiOgWtPnbr1dFPDRlq3ZtVFawOrV5ckZWVlSpK++2aLNm/aoH4PPKg/Dh2yPgrPFiov74z+OHRI2dnZZTp+XFmssTKXQ1HTE088oX79+qlLly66/fbbVa1aNR09elSfffaZCgoKFBsbW9bjRBmpXT1AHuXc9dW7T9md69etpfp1a6kHxs3Xx1/8oJ2/HJR0fkH56qQfrXXNm9SRm5urdvxyyHps++401a9bTTWr+enAoT/TzlqB5/ewyjhp+x/yoqIi7fr1z20VurW/WW5urvrymz3G3Chwjcs7k6eCgvyL1h06eP7f00oB5/+CdOTIYUnS+CdH29UePZquu7p11ugnx+nBQUMMHC1w/XKosQoODtby5cv1xhtv6PPPP1dmZqb8/f3Vpk0bjRw5UnXr1i3rcaKMLPtsq7Vh+qsPYx/R55t+1vzlG/X9T79Jkr7+bq+OZ57Ww/e1tWmsHr63nXLP5Gvthj+nHpZ/tk197mihwXe30Quz//xb9qC7W+vU6TP6Zmfp6/LO78TeQ4fST+rDtaUvpgecTV5ens6ePSsvLy+b4zt3bFfKvr26vWt367GTJ05Ym6dip0+f1gfvvyc/Pz81bhIqSWp5S6RejX3T7r2m/ft5VQsM1LBHYxQcUvIaWjgHkiRzObw4qm7dupoxY0ZZjgVlYHjf9vLzqSD//596a9/iJrm5nZ8BnrM0SXsPpGvvgfQSX/vb4RNa9fVO6/MzeQX6d3yiZj3bVx+8NkyfbfpJt4aH6IEet+jfcxJ17C8p1Kqvd2r9N3s0bkgXVfb30o97D6lr+5vVqVVDPT1jhbJz8qy1n89/XN/9eED70jIU4FdRg+5uo1rV/HXXqHjrtguAM/jwg/d16pTFuh/V1u++UWHh+S+E9L1/gCwWi/r37aUut3VVvaAgeXh4aN/eX5S46hN5e3tr6CMjrNda9p8l+vqrL9WufQdVr1FDxzIytOqTFTpy+LCenzLNurN69Ro1Vf3/98H6q9dffUmVAiqrQ3TJG5UCuDysOndyYwZ2Ut2ala3Pu7RppC5tzv/cxQerv5Ml+9IWh7+9bIPyz57V4wM6qWu7JjqUnqmnZ6zQG4vX29X2eeJtPR/TQ/fe3lwP3hmplN+P6dEXFuu9T2x3fN72c5ruim6mWoH+ys7J04atv6rfU/P0c8rhy7hj4Oq1+L0FOvzHn1PeWzZv0pbNmyRJXbvfKT9/f3Xt1lNbv/9Wn69brby8fFWrVk13dOuhoQ8PV42af/5WYFizcO38Ybs++Xi5sjKz5FnBU02ahGri5H8rsvWtdu+N6xeBlblcioqKSvyV2+HDh2vChAmqV6+ehg8fXlLJnxdxcdGcOXMubwAuLvJs9thlvRbA5Tnzw2xJUlZu4RUeCXB98avgplL+b7fMhIw1bxPvfa+xp2WpidXp06dVWFho/TMAALj2sMbKXKU2VosWLSrxzwAAACiZQ/tYrVy5UidPnizxXGZmplauXGnooAAAAK5FDjVWzzzzjH7//fcSzx08eFDPPPOMoYMCAADGcHEx7wEHG6sLLbTLysqy23MFAADgelTqGqukpCRt2LDB+nzBggWqUqWKTU1eXp7+97//qVGjRmU3QgAAcNlYvG6uUhurAwcOaP3683sTubi46Pvvv7f7VfRy5cqpQYMGevLJJ8t2lAAAANeAUhurQYMGadCgQZKk6OhoxcfHq2HDhqYNDAAA/HMEVuZyaOf14uQKAAAApXNo8foXX3yhjz76yPr8999/V79+/dSiRQs9/vjjys7OvsCrAQDAleLq6mLaAw42VvHx8bJYLNbnU6dOVUZGhgYOHKjt27dr5syZZTZAAACAa4VDjVVaWpoaNGggSTp16pQ2bdqkZ555RqNHj9aTTz7JVCEAAFcp9rEyl0ONVWFhofXrmt99950k6dZbz/96eq1atXTs2LEyGh4AAMC1w6HGKiQkRJ9++qlycnL04YcfKjw8XBUqVJAkHT16VJUqVSrTQQIAgMvj4uJi2gMONlYxMTFatWqVmjdvro0bN+rRRx+1nktOTlbjxo3LbIAAAADXCoe2W+jYsaPWrl2rn3/+WQ0aNFC9evWs5yIiIqzrrwAAwNWFIMlcDjVWklS7dm3Vrl3b7njfvn0NHRAAAMC1yuHGSpJ2796t/fv3Kz8/3+7c3XffbdigAACAMVj7ZC6HGqusrCw9/PDD2rlzp1xcXFRUVCTJ9h8WjRUAALjeObR4ffr06Tpz5oxWrlypoqIiJSQk6KOPPtLAgQNVu3Ztffzxx2U9TgAAgKueQ4nV5s2b9dRTT6l+/fqSJB8fHzVp0kRNmjSRh4eH4uLiFBcXV6YDBQAAl46pQHM5lFidOHFCgYGBcnNzU8WKFZWZmWk916ZNG23evLnMBggAAJzPb7/9psmTJ+uuu+5S48aN1aNHjxLrkpKS1KtXL4WGhqpz585atGhRiXUJCQmKjo5W06ZN1bt37xJ7k+zsbE2ePFmRkZEKDw/X8OHDdfDgQbu6AwcOaOjQoQoPD1erVq00ZcoU5ebmOnRfDjVWNWrU0IkTJyRJ9erV0xdffGE9t3XrVutmoQAA4Opytf6kza+//qqkpCTVrVtXwcHBJdZs375dMTExatSokebNm6fevXtr2rRp+uCDD2zqEhISFBsbq/79+2vu3LmqV6+eHnnkEe3Zs8em7qmnntL69ev13HPPKTY2VkePHtXgwYNtmiaLxaKBAwfq9OnTmjVrliZMmKDExEQ9++yzDt2XQ1OBt956q/73v//ptttu08CBAzVhwgT9+OOP8vDw0M6dOzVkyBCH3gwAAECSoqOj1blzZ0nShAkTtGvXLrua2bNnq3Hjxpo2bZokqVWrVjp8+LBmz56tvn37ytXVVfn5+ZozZ44GDhyooUOHSpJuueUW9ezZU3PmzNGsWbMkSTt27NDXX3+tt99+W1FRUZKkm266SV26dNGKFSvUv39/SdLSpUtlsVi0cuVKBQQESJLc3Nw0duxYxcTEWJdFlcahxGrcuHF64oknJJ3/9t+bb76poKAgVa1aVc8995yeeuopRy4DAABMdrX+pI2r64VbkPz8fG3ZskXdunWzOd6jRw9lZGTop59+kiRt27ZNp06dUvfu3a01bm5u6tq1q5KTk607GSQlJcnHx0ft2rWz1tWsWVMRERFKTk62HktOTlarVq2sTZUk3X777fLw8LCpK41DiVX58uVVvnx56/MuXbqoS5cujrwUAABcJywWiywWi91xX19f+fr6XtK10tLSVFBQYDdNWJwYpaamKjQ0VCkpKZJkVxcSEqKcnBylp6erevXqSklJUVBQkF1DFxISoo0bN1qfp6Sk6J577rGp8fDwUJ06dZSamnrRcTvUWO3Zs0fp6enW6OyvkpKSFBgYqIYNGzpyKQAAYCIzvxS4cOHCEncJGDlypEaNGnVJ18rKypIku4as+HnxeYvFIg8PD3l6etrU+fn5SZIyMzNVvXp1WSwW+fj42L2Pr6+v9VrF1yupCfx7XWkcaqymTZumiIiIEhurnTt3atu2bXrnnXccuRQAAHBSgwYNUq9eveyOX2padS1zOLEaNmxYieeaNWumxYsXGzooAABgDDP3sbqcKb/SFCdOf59aLH5efN7X11f5+fnKy8uzWbZUnC75+/tb6w4fPmz3PhaLxXqt4rqSpjMtFouCgoIuOm6HFq/n5+eX+PuAxefy8vIcuQwAAIBD6tSpo3Llytmta9q3b58kWZuc4rVVxWutiqWkpMjLy0uBgYHWuv3791sXs//1en9tmIKDg+2ulZ+fr7S0NOMaq0aNGmqR7jsAACAASURBVOnTTz8t8dwnn3zC+ioAAK5SV+s+Vhfj4eGhVq1aae3atTbHExMTVbVqVTVp0kSSFBERIR8fH61Zs8ZaU1hYqLVr16pdu3bWxC4qKkoWi0UbNmyw1h0+fFjbtm1T+/btrcfat2+vLVu26OTJk9Zj//3vf5Wfn1/ikqi/c2gq8NFHH9WIESP0yCOPqHfv3qpWrZqOHj2qFStWaOPGjYqPj3fkMgAAAJKk3NxcJSUlSZIOHTqk7OxsrVu3TpIUGhqqWrVq6bHHHtOAAQM0adIk9ezZU9u2bdOyZcs0efJk67f7PDw8NGLECMXGxiogIECNGzfWsmXLlJaWphkzZljfLywsTB06dNDEiRM1YcIEeXt7a9asWapRo4Z69+5trevXr58WL16smJgYxcTE6Pjx43r55ZfVrVs3hYSEXPS+XIr+nomVYs2aNZo+fbqOHDkiFxcXFRUVqXr16ho/frzdHhOXwsXFRZ7NHrvs1wO4dGd+mC1JysotvMIjAa4vfhXc7KaiylrLF7827b2+m9jB4dqDBw+qU6dOJZ576aWXrM1OUlKSXn/9daWkpKhatWoaPHiwBg4caPeahIQELV68WMeOHVP9+vU1btw4tW7d2qYmOztb06dP17p165Sfn6/IyEhNmjRJtWvXtqnbv3+/pk6dqq1bt6p8+fLq3r27xo0b59AvzVy0sSooKNDOnTt1ww03KDAwUKmpqcrMzJS/v79Dc40XHQCNFWA6GivgyqCxcn4XnQp0c3PToEGDNG/ePAUGBhrSTAEAAHOYuY8VHFi87urqqtq1a9ss4gIAAIA9h74VGBMTo/j4eB05cqSsxwMAAHDNcuhbgatXr1ZmZqa6dOmiBg0aqEqVKjbnXVxcNGfOnDIZIAAAuHxmbhAKBxur06dP68Ybb7R5DgAAAFsONVaLFi0q63EAAIAyQGBlLofWWAEAAODiHEqspPO/k5OcnKz9+/eX+NuAI0eONHRgAADgn2ONlbkcaqyOHDmi+++/X+np6SoqKpK7u7sKCgoknd9K3t3dncYKAABc9xyaCpw2bZpq1aqlTZs2qaioSEuXLtWWLVv07LPPKjAwUMuWLSvrcQIAgMtwrf4I87XKocZq+/btGjRokPz8/CSd/9Vof39/DRw4UPfdd5+mTJlSpoMEAAC4FjjUWGVnZ8vf31+urq7y8fHRsWPHrOdCQ0O1Y8eOMhsgAAC4fC4uLqY94GBjVbt2bWVkZEiSQkJCtHLlSuu5zz//XP7+/mUzOgAAgGuIQ4vXO3bsqM2bN6tbt24aPny4HnvsMbVq1Uru7u46fvy4xo0bV9bjBAAAl4EgyVwONVZPPPGE9c9RUVFasmSJvvjiC+Xl5alNmzaKiooqswECAABcKxzex+qvmjZtqqZNmxo9FgAAYDDWPpnrkhurM2fOaPny5UpJSVHVqlXVq1cv1ahRoyzGBgAAcE0ptbGKjY3V+vXrtWrVKuux3Nxc3XvvvUpNTVVRUZEkaeHChVq+fLlq165d9qMFAACXhMTKXKV+K3DTpk2Kjo62ObZw4UKlpKRoxIgR2rp1q5YvXy4vLy+99dZbZT5QAACAq12pjdXvv/+u0NBQm2Off/65atasqdGjR8vLy0s333yzhg0bpu+++67MBwoAAHC1K7WxysvLk4+Pj/V5Tk6OfvnlF7Vu3dqmrn79+kpPTy+7EQIAgMvGT9qYq9TGqlatWtq9e7f1+TfffKPCwkJFRkba1OXk5MjLy6vsRggAAHCNKHXxeteuXfXWW28pICBAVapU0euvvy5vb2917NjRpm7r1q2qW7dumQ8UAABcOhavm6vUxmrYsGHasWOHxo8fL0mqWLGiXnzxRZvpwby8PK1YsUL9+vUr+5ECAABc5UptrDw9PTVv3jylpaUpKytLN954o7y9vW1qzp49q7feeovECgCAqxSBlbkuukFonTp1Sj1X/M1AAAAAXOZP2gAAgGsDa6zMVeq3AgEAAHBpSKwAAHBiBFbmIrECAAAwiEONVVxcXKm7qx89elRxcXGGDgoAABjD1cXFtAccbKxmz559wcZq9uzZhg4KAADgWuTQGquioqJSzx09elS+vr6GDQgAABiHIMlcpTZWiYmJSkxMlHT+q5qvvPKKza7rkpSfn68ff/xRzZs3L9tRAgAAXANKbawKCgp0+vRpSecTq9zcXLm62s4cenh46O6779awYcPKdpQAAOCysI+VuUptrHr16qVevXpJkh588EG98MILCg4ONm1gAAAA1xqH1lgtWrTI+ueioiKdPn1aXl5edMEAAAB/4fAGod9++63i4uK0fft2nT17Vu7u7oqIiNCoUaPUokWLshwjAAC4TK5kIKZyqLHauHGjHn30UQUFBenRRx9VlSpVdOzYMX322WcaPHiw5s6dq1tvvbWsxwoAAHBVc6ixmjlzpjp27Kg333zTZvpv5MiReuyxxzRz5kwaKwAArkIs2zGXQxuE7t27V3369CnxH07fvn21d+9ewwcGAABwrXEosfL29i515/X09HRVrFjR0EEBAABjEFiZy6HEqmPHjpoxY4Y2bNhgc3zjxo2KjY1Vp06dymRwAAAA1xKHEqvx48dr7969evjhh+Xt7a3KlSvr+PHjOn36tEJDQzV+/PiyHicAALgMLiKyMpNDjZWfn5/+85//6KuvvtLWrVtlsVjk5+en5s2bq0OHDnY7sgMAAFyPHN7HytXVVZ06dWLaDwCAawj7WJmLqAkAAMAgpSZW4eHhDu994eLioq1btxo2KAAAYAz2sTJXqY3VkCFDLvoPY+vWrdq8eTP/0AAAAHSBxmrUqFGlvuj7779XXFyctmzZosaNGysmJqZMBgcAAP4Zsg9zObx4XTr/Q8yzZ8/Wt99+q0aNGik+Pl7R0dFlNTYAAIBrikON1ZYtWzR79mx99913atKkieLj49WxY8eyHhsAAPiHXImsTHXBxmrz5s2Ki4vT1q1bFRoaqrlz5yoqKsqssQEAAFxTSm2s7r//fv3www8KCwvTvHnz1K5dOzPHBQAAcM0ptbHavn27JOmXX37R448/fsGLsN0CAABXJ2YCzVVqYzVy5EgzxwEAAHDNo7ECAMCJsdekufhJGwAAAINc0j5WAADg2kJgZS4SKwAAAIOQWAEA4MTYINRcJFYAAAAGIbECAMCJkVeZi8QKAADAICRWAAA4MfaxMheJFQAAgEFIrAAAcGKuBFamIrECAAAwCIkVAABOjDVW5iKxAgAAV8QXX3yhe++9V+Hh4br11ls1atQoHThwwK5u5cqVuuOOOxQaGqru3btrzZo1djUFBQWaMWOG2rZtq7CwMA0YMEC7d++2q8vIyNCYMWPUvHlztWjRQmPHjtWJEycMuycaKwAAYLrNmzdr5MiRCgoKUlxcnCZNmqTU1FQ99NBDys7OttatW7dOTz/9tLp06aJ58+apdevWevLJJ5WUlGRzvZdeeknvv/++Ro8erfj4eJUrV06DBw9Wenq6tebs2bMaNmyY9u7dq1deeUVTp07V9u3bFRMTo6KiIkPui6lAAACc2NU6E5iYmKiaNWvqlVdesU5X1qpVS/fdd5+2bt2qqKgoSdKsWbN0xx136KmnnpIktWrVSqmpqXrzzTetNenp6Vq6dKkmTpyoPn36SJLCwsLUqVMnLVy4UOPHj5ckff7559qzZ48SExNVv359SVK1atV0//33Kzk52Xq9f4LECgAAmO7s2bPy8vKyWQPm4+NjU/P7778rNTVV3bt3tzneo0cP/fjjj9YpvI0bN6qwsFDdunWz1nh7e6tjx45KTk62HktKStJNN91kbaokKSIiQrVq1bJLwC4XjRUAAE7MxcXFtMel6NWrl1JTU7Vo0SJZLBYdPHhQr7zyioKDg9W6dWtJUmpqqiQpODjY5rUhISE251NSUlSlShVVqlTJru7AgQM6d+6cta74tX+vK77WP8VUIAAAMITFYpHFYrE77uvrK19fX5tjrVq10ptvvqmxY8dq6tSpkqSbbrpJ77zzjjw8PCRJWVlZ1tf/lZ+fn815i8Vil3YV1xUUFCgnJ0fe3t6l1vn6+iolJeVSb7dENFYAADgxMzcIXbhwoeLi4uyOjxw5UqNGjbI5tm3bNj399NO69957FR0drczMTMXHx2vEiBFasmSJPD09zRq2oWisAACAIQYNGqRevXrZHf974iRJU6dOVWRkpJ599lnrsWbNmqlDhw765JNP1LdvX2syZbFYVLVqVWtdcVJVfN7X11enTp2ye4+srCyVK1dOFStWvGCdxWKxXuuforECAMCJmblBaElTfqVJSUlRdHS0zbHq1aurUqVKSktLkyQFBQVJOr+W6q/rrIqn7YrPBwcH6/jx48rMzJS/v79NXb169eTq6mqtK2lvq3379qlDhw4O3uWFsXgdAACYrmbNmvrpp59sjh06dEgnT55UrVq1JEm1a9dWUFCQ3YagiYmJCg0NVUBAgCSpbdu2cnV11dq1a601p0+f1vr169W+fXvrsaioKO3du9dmPdUPP/ygQ4cOGbLVgkRiBQCAU7tKt7FS//79NWXKFE2ZMkWdOnVSZmam5syZo8qVK6tr167WutGjR+uJJ55QnTp11KZNG3355ZfatGmT5s6da60JDAxUv3799Nprr8nd3V01a9bUggULJJ2fnix22223qUGDBho9erSefPJJFRYWavr06QoPD7dpwP4JGisAAGC6/v37q1y5clqyZIlWrFghLy8vhYWFaebMmTbbJnTt2lVnzpzRW2+9pYSEBNWpU0czZsywS5ieeeYZVaxYUTNnztSpU6cUGhqqd955R4GBgdYad3d3zZ8/Xy+++KLGjRsnFxcXdejQQRMnTjRsytSlyKg93C93AC4u8mz22JUcAnDdOfPDbElSVm7hFR4JcH3xq+Bm2E+nOGrYf3aZ9l7z+95s2ntdrVhjBQAAYBCmAgEAcGJX628FOisSKwAAAIOQWAEA4MTM3McKJFYAAACGobECAAAwCFOBAAA4MWYCzUViBQAAYBASKwAAnJgrkZWpSKwAAAAMQmIFAIATI7AyF4kVAACAQUisAABwYmwQaq6rorE688PsKz0E4LrkV8HtSg8BAJzKVdFY5RYUXekhANeVCuXO/w224j0LrvBIgOtLzkdDTH9P1vyYi88bAADAIFdFYgUAAMoGa6zMRWIFAABgEBIrAACcmCuBlalIrAAAAAxCYgUAgBMjsTIXiRUAAIBBSKwAAHBifCvQXCRWAAAABqGxAgAAMAhTgQAAODEWr5uLxAoAAMAgJFYAADgx1q6bi8QKAADAICRWAAA4MVciK1ORWAEAABiExAoAACdGgmIuPm8AAACDkFgBAODEWGJlLhIrAAAAg5BYAQDgxPhWoLlIrAAAAAxCYgUAgBMjsDIXiRUAAIBBSKwAAHBiriRWpiKxAgAAMAiNFQAAgEGYCgQAwImx3YK5SKwAAAAMQmIFAIATI7AyF4kVAACAQUisAABwYmy3YC4SKwAAAIOQWAEA4MRcRGRlJhIrAAAAg5BYAQDgxFhjZS4SKwAAAIOQWAEA4MRIrMxFYgUAAGAQEisAAJyYC1uvm4rECgAAwCAkVgAAODHWWJmLxAoAAMAgNFYAAAAGYSoQAAAnxtp1c5FYAQAAGITECgAAJ+ZKZGUqEisAAACDkFgBAODE2G7BXCRWAAAABiGxAgDAibHEylwkVgAAAAYhsQIAwIm5isjKTCRWAAAABiGxAgDAibHGylwkVgAA4IpZuXKlevfuraZNmyoyMlIPPfSQTpw4YT2flJSkXr16KTQ0VJ07d9aiRYtKvE5CQoKio6PVtGlT9e7dW5s3b7aryc7O1uTJkxUZGanw8HANHz5cBw8eNPR+aKwAAHBiri7mPS7VnDlz9K9//UtdunTRvHnz9OKLLyokJEQFBQWSpO3btysmJkaNGjXSvHnz1Lt3b02bNk0ffPCBzXUSEhIUGxur/v37a+7cuapXr54eeeQR7dmzx6buqaee0vr16/Xcc88pNjZWR48e1eDBg5Wbm3vZn+/fuRQVFRUZdrXLGYCLi3ILrugQgOtOhXLn/wtY8Z4FV3gkwPUl56MhMvv/dt/afMC09xreup7DtampqerZs6fi4uLUsWPHEmuGDRumrKwsLVu2zHrsueee01dffaXk5GS5uroqPz9fbdq0UZ8+fTR+/HhJUmFhoXr27Kn69etr1qxZkqQdO3aoT58+evvttxUVFSVJ+uOPP9SlSxc9++yz6t+//2XetS0SKwAAnJiri4tpj0uxYsUK1axZs9SmKj8/X1u2bFG3bt1sjvfo0UMZGRn66aefJEnbtm3TqVOn1L17d2uNm5ubunbtquTkZGsjm5SUJB8fH7Vr185aV7NmTUVERCg5OfmSxn4hNFYAAMAQFotFBw8etHtYLBa72h07dqhBgwaKj4/XrbfeqiZNmujee+/Vt99+K0lKS0tTQUGBgoODbV5Xv359SecTL0lKSUmRJLu6kJAQ5eTkKD093VoXFBQkV1dXu7riaxmBbwUCAABDLFy4UHFxcXbHR44cqVGjRtkcy8jI0K5du7Rnzx5NnDhR3t7eWrBggYYNG6Y1a9YoKytLkuTr62vzuuLnxectFos8PDzk6elpU+fn5ydJyszMVPXq1WWxWOTj42M3Nl9fX+u1jEBjBQCAEzNzu4VBgwapV69edsf/3hxJUlFRkXJycrRkyRI1atRIktSyZUt16tRJCQkJ6tGjR5mPtyzQWAEAAEP4+vqW2ESVVuvv729tqiSpQoUKCgsL06+//mpNnP4+jVj8vPi8r6+v8vPzlZeXp/Lly1vrilMof39/a93hw4ftxmGxWKzXMgJrrAAAcGJX6+L1kJCQUs/l5eWpTp06KleunN36p3379kmSgoKCJP25tqp4rVWxlJQUeXl5KTAw0Fq3f/9+u29l7tu3z3otI9BYAQAA03Xs2FGZmZnWb/dJUk5Ojn744Qc1adJEHh4eatWqldauXWvzusTERFWtWlVNmjSRJEVERMjHx0dr1qyx1hQWFmrt2rVq166dXP6/4YuKipLFYtGGDRusdYcPH9a2bdvUvn17w+6LqUAAAJzY1fqTNp07d1bTpk01evRoPfHEE/Ly8tKCBQt05swZPfTQQ5Kkxx57TAMGDNCkSZPUs2dPbdu2TcuWLdPkyZOt3+7z8PDQiBEjFBsbq4CAADVu3FjLli1TWlqaZsyYYX2/sLAwdejQQRMnTtSECRPk7e2tWbNmqUaNGurdu7dh98UGocB1iA1CgSvjSmwQuuC7NNPea0jLOpdUf+LECU2fPl1ffvml8vLyFBYWpvHjxys0NNRak5SUpNdff10pKSmqVq2aBg8erIEDB9pdKyEhQYsXL9axY8dUv359jRs3Tq1bt7apyc7O1vTp07Vu3Trl5+crMjJSkyZNUu3atS/vhktAYwVch2isgCvjSjRW75rYWA2+xMbKGbHGCgAAwCCssQIAwIm5XK2LrJwUiRUAAIBBSKwAAHBi5FXmIrECAAAwCIkVAABO7FJ3RMc/Q2IFAABgEBIrAACcGHmVuUisAAAADEJjBQAAYBCmAgEAcGKsXTcXiRUAAIBBSKwAAHBi/KSNuUisAAAADEJiBQCAEyNBMRefNwAAgEFIrAAAcGKssTIXiRUAAIBBSKwAAHBi5FXmIrECAAAwCIkVAABOjDVW5iKxAgAAMAiJFQAATowExVx83gAAAAYhsQIAwImxxspcJFYAAAAGobECAAAwCFOBAAA4MSYCzUViBQAAYBASKwAAnBhr181FYgUAAGAQEisAAJyYK6usTEViBQAAYBASKwAAnBhrrMxFYgUAAGAQEisAAJyYC2usTEViBQAAYBASKwAAnBhrrMxFYgUAAGAQEisAAJwY+1iZi8QKAADAICRWAAA4MdZYmYvECgAAwCA0VgAAAAZhKhAAACfGVKC5SKwAAAAMQmIFAIAT4ydtzEViBQAAYBASKwAAnJgrgZWpSKwAAAAMQmIFAIATY42VuUisAAAADEJiBQCAE2MfK3ORWAEAABiExAoAACfGGitzkVgBAAAYhMQKAAAnxj5W5iKxAgAAMAiJFQAATow1VuaisYJ27/5Zs9+Yqe3btupsYaGaNLlZI0ePUUTzFjZ1P+7cqVWffKxdP+7U3r2/qKCgQF9+vVFVqlYt8brHjx/XnNlvKOnrr3TyxAlVqVJVzcIj9PKrM8y4LeCK8fJ015g7b1bzkKqKCK6iqn6emrz4e81Y+aO1xsVF6h8Vojsj6yrsxsqq5O2h345ma9mm/Zr16S7lFRRaa2tV9tLA6Pq6I+IGBdfwVeG5Iv38+0lNX75DX/142O79mwVV1sQ+zRQRXEXenuWUdixbHySlaPbqn22uK0mRDappyoDmCg+qouzcAn285YCeW/y9Tp85W3YfEODEaKyuc3t279bgBx9QQECAhj0yXO7u5bTy44/0yNDBmrdgocIjmltrN25I0kfLP1RwSH3VrXej9v26t9TrHjl8WIMffEBFRUW6594+CqxeXccyMvT999+ZcFfAlVXZx1PP9gnXwWOntfPAcXUKq2VXU7G8u+aObKdvfjmq+Z/vUYbljCJvqqpJfZqpY9Ma6vr8Omttj5Z19OTdoUr89je9n7RP7q6ueiAqWInP36ER8Rv13vpfrbXNgipr/YvdlXLEolmf7lL2mbNqf3N1TRnQQk1vDNDg2CRrbdN6AVo9+Xbt/SNLzyz8VjUDvDS6ZxPVr+GrnlM+L9sPCXBSNFbXubg3Z8rdzU2Ll3yoylWqSJLuua+P7u7ZVa++PE1LPvzIWtun7/16aOjD8vT01JzZb16wsZryr8lydXPVkv8sl79/Jevxhx8dUXY3A1wljpzMUfDDS3XkZK7qVPXW7jn32dXknz2n6Imr9c0vR63H3v1ir347mq3n+kWoc1hNfbHjD0lS8q7Dajj8Qx0/lWetnf/5Hm1+7S5N7hdh01gN7dJALpJuf26tTmSfr1/w31/k4e6m3q3qKab8JuXknU+jXniguSw5+brj+bWy5BRIkn7LOKX4EW11e/gN+mz7QcM/G5iPDULNxeL169z2rd+rZWQra1MlSRUrVlSHjp3000+7lPbbb9bjlatUkaen50WvuT81RRs3JGvwQ0Pl719JeXl5KsjPL5PxA1ej/LPndORk7gVrCs6es2mqiq36Nk2S1LC2v/XY7oOZNk1V8Xt8vu2gagRUlL+Xh/W4b0UPnSko1MnTtvVHTuao8FyR8s+enwr0qVBO0U1r6sONqdamSpKWJKXoVG6Berep59jNArBBY3Wdy8/PV4USmqXiYz/9tOuSr7ll82ZJUkDlKnpk6GBFNg9TZItmevThIfo9Le0fjRdwdoH+FSRJxy15F6mUAitVUG7eWWWf+bMx2vjzEflW9FD8iFvV8AY/3VDFS/2jQvRgx/qK/WSXzhYWSZKa1Kmkcu6u2pZy3OaaBWfPaeeB4wq7sbKBd4UrycXEBy5hKjA2NlYnT57Uv//9b7tzkydPVuXKlfX4448bOjiUvXr1btSOHT/o7Nmzcnf/838OW7d+L0k6ejT9kq+ZlnZAkjTlhefU5OZQTZ8Rq/Qj6Xor/k09PGSQlq9cJW9vb0PGDzibJ+66WZacfH227cLTcEHVfXTnLXX16be/WZsl6fy0X6Pa/hrSuYEGRt8kSTp3rkj/+mCrXvv4z8Xz1Sudb+COnMyxu/aRk7m6qaa/3XEAF+dwYpWYmKiIiIgSzzVv3lyrV682bFAwT78HBujQwYOa9MzT+nXvL9qfmqJpU/+t3T//LEnKO3Pmkq+Zk3P+P9SVq1RV3Jy3ddvtXfXgoMF68aXpOnz4D33y8UcXuQJwfRrbu6miw2pp8vtbreujSlLBw02Ln+qo3PxCTVr0vc25wnNFSjls0dc//qHhszfogVfX64PkFD1/f3M9ckfDv1zj/F+k8s6es7t+XkGhKni4GXRXuNJcXVxMe+ASEqujR4+qRo0aJZ6rXr26jhw5YtigYJ577uujo0fTtWD+21q7JlGSVLdePY16fIxiZ7wqLy+vS75m+fLnpxFvu/0Oubr+2bt3iO4kLy8v/bB9m/o/OMiYGwCcxD1tbtTz/SL07hd7Ne+zPaXWubq6aOETHdTwBn/1evG/+uOEbeL01N2hGtWziZqO+si6duqTb36Ti4v04oMtteJ/+3XMkqfc/PML2Mu72//9unw5N+XmF9odB3BxDidWAQEB2ru35G+B7d27V35+foYNCuYa8dgofbVhsxYu/kBLl63QylVr5fX/U3V169W75OtVq1ZNkmwWxBcLCKgsi8Xyj8YLOJvopjU1b1Q7rdv2u0a//b8L1s4e3kZdm9fWo3EblLTLfg+rh29vqKRdR2wWpEvnF8VXLO+u8KDz/14WL66vXqmi3TWqV6pQ4hQhrk2ssTKXw41V586dFRcXp507d9oc37lzp+Lj49WlSxfDBwfzeHt7q1l4hBo1biJXV1dt3rRJnhUqqFl484u/+G8aNW4iSTqabrs+69y5c8o4lqFKlQIMGTPgDFrUr6IPxkVrW8oxPfj61yo8V1Rq7YsPttDA6Jv09Lvfatmm/SXWVPOvIHc3+/+Lc///H4xz+/9zP/9+UgVnzyki2HaRejl3VzWtV1k7D5y43FsCrmsON1ZjxoxRzZo11bdvX/Xo0UNDhgxRjx491LdvX9WoUUNPPPFEWY4TJtr6/Xf6av0Xuuee+y5rkXnLWyIVULmy1qxepby8P9eJrE78VGdyc9WqTRsjhwtcsxrU8tNHz3RRWka27n3pC525wPTbmDtv1pi7QjX9ox2KX/NzqXW//pGlqJtrqJqf7bd9+7YPVmHhOe3Yf75hsuQU6Ksf/1CftkHyqVDOWnd/+2D5VCinFZtLbtxwDboGIqvTp0+rffv2atCggX788UebWLgxvQAAIABJREFUcytXrtQdd9yh0NBQde/eXWvWrLF7fUFBgWbMmKG2bdsqLCxMAwYM0O7du+3qMjIyNGbMGDVv3lwtWrTQ2LFj/6+9e4+rKW37AP7bUSiSpMIIxQ5JB4dyqmQYhyeEQePQvBmh0oxmCM0YxnjETHLITErOZzlMeooZ5PjmGYrH4BEqx4hJ5+OW9f7hbc1sJTtWO/L7zsfno3vda61rNbtc+1r3ujaePJH2TYTKa6waNWqEXbt24cCBAzh79iyysrIgl8vh7u6O4cOHQ0tL69UHobdOwvlz+HnNavTq3Qd6TZog6do17N+7Bx07WcDH9wuluWlp9xEd9Yu4HwBs3bIJ2traaN6iBVyGjQAAaGlpwe+r2fh6rj/+Z9J4/GPYcKQ/fIjtWzfDwqIzhg51Ue9FEtWAqYM6orGOlthjyqFzc9Sp8/y9bGjsVTx7JuCXrweiiY4WVkZdxiDbD5T2T0nPxe/XHwMAXHqYYPGk7riRlo2ke1kY19dUae6xS2l4lP38QZMf913CxplOOBHogohfryGnUIF/dDdBf6uWiPg1CQ/+tiZr4fZEHF08BIe/G4yI35LQQl8bn7t0xvE/0nAogc1BSX1CQkJQWlr+jcWhQ4fg7+8PT09P9O7dG0eOHIGfnx90dHTg6OgozluyZAkOHDiAOXPmoGXLlli3bh0+/fRTREVFwcjICADw9OlTfPbZZ1AoFFi6dCmePn2KH374AV5eXtixYwdkEi2+lwmC8PK6sxrIZDIUKmo0hPfa3Tt38M/vF+K//72KvNxcNG/eAh8NHoLJU6aiQYMGSnPP/f5vfPY/kyo8TrfuPRCxcYvS2KHYGKwPX4vU1BToNGyI/h8OwOdffAldrsercQ00n/8C0R61voYjqb2u/jQarQ0bVbit4/Q9AFBhR/YyW+NuYOqa0wCAeWOsETDG5qVzB30bi1NX/nqAyMmyOWaN7IJOrZqgsY4WUtNzse34TayIuoxnL9xq7NnBEN+N7wYb06bIK3qK/fGpmL8tAbmFihdPQxIo2OsBdf+z++/kbLWdy86s6r/fr1+/jrFjx2LOnDmYP38+IiMjYWlpCQAYPHgw5HI5Vq5cKc738PBATk4OIiMjAQDp6eno168fAgICMH78eABAXl4e+vfvj1GjRmH27NkAgJiYGMycORPR0dFo3749ACAxMRFubm4ICwtTStTeBBMrovcQEyuimsHEqrwJEybA2toaffv2xaRJk8TE6u7du/jwww+xevVqDBw4UJy/b98+zJ07F/Hx8dDX18fevXsxb948nD17Fk2a/PURanPmzMHly5cRHf38iXd/f39cvXoVBw8eVDq/s7MznJycMH/+/Ne8amWV3gq0tbXF5s2b0blzZ9jY2FRaJpPJZEhISJAkKCIiIpLG29xe6sCBA7h9+zbWrl2Ly5eVP+kjJSUFAGBmZqY03q5dO3G7vr4+kpOTYWBgoJRUlc2Ljo7Gs2fPoKGhgeTkZHHfF+eVnUsKlSZWHh4eaNasmfh3qe4/EhERUe2Tk5NTYUsdXV1d6OrqKo3l5ubihx9+gL+/f4U9E7Ozs8V9/66svVPZ9pycHDRqVP62e+PGjaFQKFBQUICGDRu+dJ6uri6Sk5NVvMJXqzSx8vHxEf8+Y8YMyU5KRERE6qHOksimTZsQEhJSbtzHx6dcHrFixQq0bt0aw4YNU1d4aqHyU4Fz586Fl5cXWrVqVW7b/fv3ERISgiVLlkgaHBEREb073N3d4erqWm78xarTjRs3sHPnTqxfv16scJV9HFpBQQHy8vLEylROTo549wz4q1JVtl1XVxe5ubnlzpmdnQ1NTU1oa2tXOi8nJ0fSJucqJ1b79++Hm5tbhYlVZmYmDhw4wMSKiIjoPVbRLb+K3L59G0+fPsWkSeWfNJ80aRI6dOggVr5SUlKU1lmV3bYzNX3edsTMzAwZGRnIysqCnp6e0rw2bdqIH61mZmZWYW+rmzdvwsnJSfWLfAWVE6vKpKamKl0MERERvSXewuXRZQ/H/d1///tfLFmyBAsXLoSFhQVatWoFU1NTxMTEKH26S3R0NCwtLaGv//xTPPr06QMNDQ3ExsbCzc0NwPOGo8eOHcOoUaPE/RwdHfHLL78gOTlZTNQuXryI+/fvS9ZqAXhFYrV9+3bs2LEDwPOn/r766ivUq1dPaU5JSQnu3buHQYMGSRYUERER1V76+vqws7OrcJuFhYXYx8rX1xczZ86EiYkJevXqhaNHj+LMmTNYu3atON/IyAjjxo3Djz/+iLp166JFixZYv/55Kxl3d3dx3sCBA2Fubg5fX1/4+fmhtLQUy5Ytg42NDRwcHCS7tkoTK0NDQ3Tu3BnA8/uhbdu2FTPEMpqamnBzc8Po0aMlC4qIiIikIXsbS1YqGjx4MIqKihAaGoqIiAiYmJggKCioXIVp7ty50NbWxooVK5CbmwtLS0ts2LBB7LoOAHXr1sW6deuwePFizJo1CzKZDE5OTggICJC064HKDUIrW7z+RgGwQSiR2rFBKFHNqIkGoedTy7c/qC7d2r56fVVtp/Iaq4oWpmdnZyMtLQ1mZmb8rEAiIqK3EFtQqpeGqhPXrFmD5cuXi1/Hx8fDyckJI0eOxMCBAyXtWkpERET0LlI5sYqKikLr1q3Fr5cuXYouXbpgw4YNaNGiBYKDg6slQCIiInp9MjX+oSrcCkxPT4eJiQkA4OHDh7h27Rq2b98OW1tb5OfnS/bhhURERETvKpUTq3r16okdS+Pj46GjowNra2sAgI6ODvLz86snQiIiInp9LCWplcqJlZWVFcLCwqChoYH169fDwcFB7GZ69+5dGBoaVluQRERERO8ClddY+fv7IyMjA9OmTUN+fj6++OILcVtMTAxsbW2rJUAiIiJ6fTI1/kdVqFiZmZnht99+Q2ZmJpo0aaK0bc6cOUofkEhERET0PqryZwW+mFQBgLm5uSTBEBERkbTYx0q9qpRY/fnnn4iOjsatW7dQXFxcbntFTUSJiIiI3hcqJ1Y3b96Em5sbNDU1kZmZiebNmyM7Oxv5+flo2rRpuc8QJCIioprHgpV6qbx4PTAwED169MCJEycgCAJWr16NhIQErFmzBpqamli4cGF1xklERET01lM5sbpy5QrGjBmDOnXqAABKSkoAAP3798eUKVMQGBhYPRESERERvSNUvhWoUCjQoEEDaGhoQE9PD48ePRK3mZqa4vr169USIBEREb0B3gtUK5UrVm3atEFaWhoAoFOnTti2bRvy8vJQWFiIHTt2wMjIqNqCJCIiInoXqFyxcnFxQVJSEgDA19cXkydPRo8ePSCTySAIApYuXVptQRIREdHrYeNO9VI5sXJ3dxf/bm1tjejoaJw6dQpFRUWwt7eHXC6vlgCJiIiI3hVVbhBapnnz5hgzZoyUsRAREZHE2CBUvVReYxUTE4N169ZVuC0iIgKxsbGSBUVERET0LlI5sQoLC4OWllaF2+rXr4/w8HDJgiIiIiJpyNT4h6qQWN26dQvt27evcJuZmRlSU1MlC4qIiIjoXaTyGqt69eohIyOjwm2PHz9G3bqvvVyLiIiIqgtLSWqlcsWqe/fuWLt2LQoKCpTGCwoKEB4ejh49ekgeHBEREdG7ROUy08yZMzFu3DgMGDAAH330EQwNDfHo0SMcPnwYCoUCwcHB1RknERERvQb2sVIvlRMrMzMzREZGYtWqVfj111+RlZUFPT099OrVCz4+PmjdunV1xklERET01lMpsSopKUFERAScnJwQFBRU3TERERGRRNjHSr1UWmOlpaWF0NBQ5OXlVXc8RERERO8slRevW1hYiJ8VSERERO8G9rFSL5UTq4CAAGzevBkxMTEoLCyszpiIiIiI3kkqL16fMGECFAoFvvzySwDPu63L/nbjViaTISEhQfoIiYiI6PWxlKRWKidWHh4eSokUERERESlTObGaMWNGdcZBRERE9M7j59AQERHVYmwQql5VSqySkpIQGRmJW7duobi4uNz2zZs3SxYYERER0btG5acCExISMGrUKCQkJOD06dMoKSlBZmYmzp07h3v37kFbW7s64yQiIqLXIJOp7w9VIbFavnw5RowYgT179kAQBHzzzTc4ePAg9u/fDwAYPXp0tQVJRERE9C5QObG6fv06Bg0aBA2N57sUFRUBADp06ABfX1+sXLmyeiIkIiKi18YGoeqlcmKloaGBunXrQiaTwcDAAGlpaeI2AwMD3L17t1oCJCIiInpXqJxYtWvXDnfu3AEAWFtbY/369UhKSkJKSgrWrl0LExOTaguSiIiIXhNLVmql8lOBY8eOFatUM2fOhIeHB0aMGAEAaNCgAVavXl09ERIRERG9I1ROrIYNGyb+3czMDDExMbhw4QKKi4thbW2Npk2bVkuARERE9PrYx0q9XrtBqI6ODvr06SNlLERERETvtEoTqydPnuDRo0fo0KGD0vi1a9fw008/ITk5Gc2aNcOkSZPg7OxcrYESERFR1bG/lHpVunh9+fLlmDdvntLY/fv3MX78eBw9ehT16tXD9evX4ePjg3PnzlVroERERERvu0oTq8TERLi4uCiNbdy4EQUFBVi7di327duHY8eOwcrKCuHh4dUaKBEREVUdHwpUr0oTq/T0dLRv315pLC4uDh07dhTXV9WvXx8TJkxAUlJS9UVJRERE9A6oNLGSvXBj9s8//8S9e/fQvXt3pXEjIyNkZmZKHx0RERG9GZas1KrSxKpt27Y4c+aM+PWxY8cgk8nQu3dvpXmPHz+Gvr5+9URIRERE9I6o9KnAiRMnwt/fH7m5uWjatCl27NgBExMT9OrVS2ne6dOnIZfLqzVQIiIiorddpYnVsGHDkJ6ejq1btyInJwcWFhb49ttvUbfuX7tlZGQgLi4OM2bMqPZgiYiIqGrYIFS9ZIIgCDUagEyGQkWNhkD03mmg+fwXrfao9TUcCdH7pWCvB9T9z27K4yK1ncu0WX21nett9dqd14mIiOjtxwah6lXp4nUiIiIiUh0rVkRERLUYC1bqxYoVERERkURYsSIiIqrNWLJSK1asiIiIiCTCihUREVEtxj5W6sWKFREREZFEWLEiIiKqxdjHSr1YsSIiIiKSCCtWREREtRgLVurFihURERGRRFixIiIiqsW4xkq9WLEiIiIikggTKyIiIiKJ8FYgERFRrcZ7gerEihURERGRRFixIiIiqsW4eF29WLEiIiIikggTKyIiolpMpsY/VREbGwsvLy84OjrC2toaLi4u2L59O549e6Y078SJE3B1dYWlpSU+/PBDbNmypcLjRUREwNnZGV26dMHIkSMRHx9fbk5eXh7mz58POzs72NjYYNq0abh3714VI68cEysiIiJSuw0bNkBLSwuzZ89GaGgoPvzwQyxevBg//PCDOOfChQvw8vJCx44dER4ejpEjR+Kf//wnduzYoXSsiIgIBAcHY/z48Vi7di3atGkDT09PXLt2TWnel19+iWPHjuGbb75BcHAwHj16hE8//RSFhYWSXZdMEARBsqO9TgAyGQoVNRoC0Xungebz95bao9bXcCRE75eCvR5Q9z+7D7JL1Hau5o21VJ775MkT6OvrK40tWbIEO3bswPnz56GlpYXPPvsM2dnZ2LNnjzjnm2++QVxcHE6ePAkNDQ2UlJSgV69eGDNmDGbPng0AKC0thYuLC9q3b4+VK1cCAP7zn/9gzJgxCAsLg6OjIwAgLS0NAwYMwLx58zB+/Pg3vXwArFgRERFRDXgxqQKAjh07ori4GFlZWSgpKcHZs2cxZMgQpTn/+Mc/8PjxY1y5cgUAkJiYiNzcXAwdOlScU6dOHQwePBgnT54UE9kTJ06gUaNG6Nu3rzivRYsWsLW1xcmTJyW7Lj4VSEREVIvJ1NjHKicnBzk5OeXGdXV1oaur+8r9ExISoKenh6ZNmyI1NRUKhQJmZmZKc9q3bw8ASElJgaWlJZKTkwGg3Lx27dqhoKAA6enpMDY2RnJyMkxNTaGhoVFu3unTp6t0nZVhYkVERESS2LRpE0JCQsqN+/j4YMaMGZXu+8cff2Dfvn3w9vZGnTp1kJ2dDQDlErKyr8u25+TkQEtLC/Xr11ea17hxYwBAVlYWjI2NkZOTg0aNGpU7r66urngsKTCxIiIiqs3U2MfK3d0drq6u5cZfVa16/PgxfH19YWlpiSlTplRXeGrBxIqIiIgkoeotv7/Lzc3FlClTUL9+ffz888/Q1NQE8FfF6cVbi2Vfl23X1dVFSUkJiouLUa9ePXFeWRVKT09PnPfgwYNy58/JyRGPJQUuXiciIqrF3tY+VgBQXFyM6dOnIyMjA+vWrUOTJk3EbSYmJtDU1ERKSorSPjdv3gQAmJqaAvhrbVXZWqsyycnJ0NHRgZGRkTgvNTW13FOZN2/eFI8lBSZWREREpHZPnz7F559/jqSkJISHh6Nly5ZK27W0tGBvb4/Y2Fil8ejoaDRr1gwWFhYAAFtbWzRq1AgxMTHinNLSUsTGxqJv376Q/f9n+jg6OiInJwenTp0S5z148ACJiYlwcHCQ7Lp4K5CIiKgWe1s/K/C7775DXFwcZs2ahaKiIly8eFHc1q5dOzRs2BDe3t6YMGECvv76a7i4uCAxMRF79uzB/Pnzxaf7tLS0MH36dAQHB0NfXx+dOnXCnj17cOfOHQQFBYnHtLKygpOTEwICAjBnzhw0bNgQK1euRPPmzTFy5EjJrosNQoneQ2wQSlQzaqJB6KNchdrOZdhIU+W5zs7OuH//foXbNm/eDDs7OwDP+08tX74cycnJMDQ0xKeffopJkyaV2yciIgJbt27Fn3/+ifbt22PWrFno2bOn0py8vDwsW7YMhw4dQklJCezs7PD111+jVatWVbjKyjGxInoPMbEiqhlMrGo/3gokIiKqxdTZIJS4eJ2IiIhIMqxYERER1WYsWKkVK1ZEREREEmHFioiIqBZjwUq9WLEiIiIikggrVkRERLXY29ogtLZixYqIiIhIIqxYERER1WLsY6VerFgRERERSYQVKyIiolqMa6zUixUrIiIiIokwsSIiIiKSCBMrIiIiIolwjRUREVEtxjVW6sWKFREREZFEmFgRERERSYS3AomIiGoxNghVL1asiIiIiCTCihUREVEtxsXr6sWKFREREZFEWLEiIiKqxViwUi9WrIiIiIgkwooVERFRbcaSlVqxYkVEREQkEVasiIiIajH2sVIvVqyIiIiIJMKKFRERUS3GPlbqxYoVERERkURYsSIiIqrFWLBSL1asiIiIiCTCihUREVFtxpKVWrFiRURERCQRJlZEREREEuGtQCIiolqMDULVixUrIiIiIonIBEEQajQAdi4jIqL3iLr/2S16qr5z1ed9sJpPrIiIiIhqC94KJCIiIpIIEysiIiIiiTCxIiIiIpIIEysiIiIiiTCxIiIiIpIIEysiIiIiiTCxIiIiIpIIEysiIiIiiTCxIiIiIpIIE6sasHr1apibm2PcuHEVbrOxsanyMfft24eDBw+qNLewsBAhISEYMmQIrKysYGdnh1GjRiE4OLjK561pGzduxIkTJ8qNT5w4EVOnTq2BiOh9EBUVhdGjR6Nr166wtbXF4MGDERAQgIyMjJoOrUqOHDmCbdu2lRt/3d9DRATwU31q0IULF3DmzBn07t37jY+1f/9+aGtrw8XF5ZVzfX19cenSJUydOhUdO3ZEbm4u/vjjDxw5cgQzZ85841jUafPmzXBycoKjo6PS+LfffgsNDb5vIOmFh4cjKCgI7u7u8PX1BQDcuHEDBw8exKNHj9C0adMajlB1R44cweXLlzF+/Hil8Y8//rjczxQRqYaJVQ3R1tZG+/btERISIkliparbt2/j5MmTWLp0KUaMGCGODxw4UJKkqrS0FKWlpdDS0nrjY72Jdu3a1ej5qfbasmULXF1dMXfuXHHMwcEBkydPxrNnz974+MXFxahXr94bH+dNGBsbw9jYuEZjIHpX8S19DfL29kZiYiLi4+MrnZeVlYWAgAD07NkTlpaWGDVqFE6dOiVunzhxIn7//XccP34c5ubmMDc3x+rVqys8VnZ2NgDAwMCg3LYXKzzLly+Hi4sLbGxs0KdPH/j6+uLBgwdKc8puuUVFRWHQoEGwtLTEpUuXAADHjx/HuHHjYGVlhe7du2PixIm4evUqAKCoqAiLFi3CoEGDYGVlhX79+mHevHnIyspSOn5cXBxGjx4NGxsbdO3aFa6urvj1118BAM7Ozrh//z62bdsmXve+ffuU4vq75ORk+Pj4oEePHrCyssKwYcMQHR1d6fee6EU5OTlo1qxZhdv+/jP0yy+/4JNPPoGdnR26deuGTz75BOfPn1eaX3bL7fLly3Bzc0OXLl2wbt06AK9+vW7cuBGjRo1C165dYW9vj8mTJ+PGjRtKx09OToanpyfs7OxgZWWFgQMHIiQkBAAwZ84c7N+/Hzdu3BB/fubMmaMU14vXvWjRIjg4OKBz585wdnZGUFDQa34XiWovVqxqkKOjIywtLRESEoKePXtWOKe0tBRTpkzBnTt34OfnB2NjY+zatQtTp07F+vXrYW9vj2+//RazZs1C/fr14e/vDwAvfbdpamoKbW1tLF26FCUlJbCzs4OOjk6FczMyMuDp6QlDQ0NkZWVh06ZNcHNzw6FDh1C/fn1x3pUrV3D37l34+PigSZMm+OCDDxATEwM/Pz/0798fP/74I7S0tJCYmIj09HR06tQJRUVFUCgU+Pzzz2FgYICHDx8iLCwMn332GSIjIwEAd+7cwYwZMzB06FDMnDkTgiAgKSlJTA5DQkLg6ekJW1tbeHh4AABMTEwqvJZbt25h7NixMDY2RkBAAJo1a4br168jLS1Nhf9TRH+xsLDAjh070LJlSzg7O780ybp//z6GDRuG1q1bQ6FQ4NChQ3B3d8fevXvRoUMHcZ5CocAXX3yBSZMm4YsvvkDDhg1Ver0+fPgQ48ePR4sWLVBYWIjdu3dj3LhxiI2NhaGhIQBg2rRp0NfXx+LFi9GoUSPcuXMHt2/fBgB4eXnhyZMnSElJwY8//ggA0NfXr/BaSkpK4O7ujvv378PLywvm5uZ4+PAhEhISJPmeEtUqAqndqlWrBGtra0EQBCEuLk6Qy+VCfHx8uW2CIAhHjhwR5HK5cPz4cXGstLRUGDp0qDBhwgRxbMKECYKnp6dK5//Xv/4l2NjYCHK5XOjYsaPg6uoq/PTTT0J+fv5L93n69Knw5MkToUOHDsLhw4eVzmthYSHcu3dPHHv27Jng4OAgeHh4qBSPIAiCQqEQrl69KsjlcuHy5cuCIAhCbGysIJfLhdzc3Jfu169fP2HhwoXlxl/8fvj5+Qn29vaVHotIFUlJScKAAQMEuVwuyOVywdnZWVi0aJFw9+7dl+5TWloqKBQKwdXVVVi0aJE4vmrVKkEulwtRUVFK86v6en369KlQXFws2NvbC+vXrxcEQRAyMjIEuVwuHD169KX7+fv7C0OHDi03/uLvoV27dglyuVxITExUKR6i9xkrVjXMyckJFhYWWLNmDezt7cttP3/+PHR0dJQWkmpoaGDQoEEIDQ1FaWkp6tSpU6VzDhkyBL1790ZcXBz+/e9/4+zZs1ixYgWioqKwd+9eaGtrAwBOnDiBn3/+GTdv3kRubq64/61bt5SOJ5fL0bJlS/HrlJQUPHz4UKyevcyBAwewadMm3Lp1CwUFBUrHt7CwgLm5OerUqYOvvvoKH3/8Mbp37w5dXd0qXWuZs2fP4qOPPkLDhg1fa3+iMnK5HNHR0YiPj8fp06dx7tw5bNmyBfv27cO2bdvQsWNHAM9vwwUHB+PChQv4888/xf2bNGlS7pjOzs5KX6vyer148SJWrVqFK1euKN1CT01NFc/TsmVLLF++HFlZWejZsyeaN2/+WtccHx8PMzMzPilIpAKusXoL+Pj44Pfff8e5c+fKbcvJyalwPVTTpk2hUCiUEpKqaNy4MUaMGIElS5bg2LFj8PLyQkpKingb7tKlS/Dy8oKBgQECAwOxa9cuREZGQlNTE8XFxUrHejG+sl/yZbcjKvLbb7/B398fFhYWWLFiBXbv3i2uLSk7ftu2bREaGoq8vDz4+vqiZ8+e8PT0xN27d6t8vVlZWZXGQ1QVWlpacHR0REBAAA4cOIB169ahqKgIa9asAQDk5eXBw8MDd+/exezZs7Ft2zZERkbCxsYGJSUlSsdq0KBBudvxr3q9pqWlwcPDAwqFAgsWLMD27dsRGRmJli1biseXyWSIiIiAmZkZFi1aBCcnJwwfPvyVazorwp8fItWxYvUWcHZ2hoWFBUJCQtCtWzelbY0bN1Z6t1smIyMDmpqaYnXpTchkMkyePBk//fQTkpOTATx/DLthw4ZYuXKlWBHLzMyEQqGocP+/09PTAwA8evTopec8dOgQOnTogO+//14cu3z5crl5Dg4OcHBwQH5+Ps6cOYPAwEB8+eWX2L17d5WuUU9Pr9J4iN5E37590aFDB/Hn5+LFi3j48CFCQ0PFChYA5Ofniz8fZV78+QFe/Xo9deoUCgoKEBISgsaNG4vjLz780bZtW6xcuRJPnz4VK1zTp09HXFxchZWzl9HT00NSUpLK84neZ6xYvSW8vb1x9uzZcotBu3btivz8fJw8eVIcEwQBhw8fho2NjZj0VFRJqkheXh6KiorKjZfd3itbiFtUVIS6desqPeWkagNSU1NTGBsbi0/oVaSoqKhcS4bKjq+jo4OBAwdi+PDhuHnzpjiu6nX37NkThw8fRl5engpXQPRyFb3RKSoqwoMHD8TqbdnP2N9f49euXSv31N7LvOr1WlRUBJlMhrp1/3pvfPToUeTn51c4v27duujWrRumT5+OwsJCcRG8qj8/vXr1QnJyMv7zn/+oFD/R+4wVq7dE//790alTJ8THxytVoZycnNClSxfMnj0K4LCPAAADeklEQVQbfn5+MDIywu7du5GcnIwNGzaI80xNTbF//34cPXoUhoaGMDQ0hJGRUbnzpKamYvr06XB1dUXXrl2hra2NmzdvIjw8HI0aNYKrqysAoHfv3ti0aRMWLlyIjz76CH/88Qd2794NTU3NV16LTCaDv78//Pz8MGPGDAwfPhxaWlq4ePEiLC0t0a9fP/Tq1QvfffcdVq9eja5du+J///d/cezYMaXj7Ny5E4mJiXBwcIChoSHS0tIQGRmp1PfL1NRUXOvSuHFjfPDBBxW+E/fx8cHx48fh5uaGKVOmoFmzZkhOTkZhYSGmTJny6v9BRP/PxcUF/fr1Q58+fWBoaIj09HRs3boVmZmZcHd3BwBYW1tDW1sbCxYsgKenJzIyMrBq1SqVe0O96vVath5z7ty5GDduHFJTUxEWFqb0VN+1a9cQGBiIIUOGoFWrVigoKMC6detgaGgo9nkzMzNDZGQkoqKi0LZtW/Gp3hcNHz4c27dvh6enJ7y9vSGXy5Geno7z589j0aJFb/otJapVmFi9Rby9veHt7a00VqdOHYSHh2PZsmUICgpCQUEB5HI5QkNDYWdnJ84ra8kwZ84c5OTkwMfHBzNmzCh3jtatW2Ps2LE4c+YM9uzZg/z8fBgZGcHe3h7Tpk0TF6E7Ojpi1qxZ2LJlC/bv348uXbrg559/xpgxY1S6liFDhqB+/foIDQ2Fn58f6tWrh06dOmHAgAEAgHHjxuHevXvYuXOn2DZi1apVSk1Lzc3Ncfz4cSxduhSZmZkwMDDAgAEDlBqZ+vn5YcGCBfD19UV+fj6WLFmCkSNHlounTZs22LlzJ4KCgrBw4UKUlpaiTZs28PT0VOl6iMr4+PggLi4OgYGBePLkCZo0aQJzc3Ns3LhRTHgMDAywatUqLFu2DN7e3jAxMcHcuXMRGRmp0rrIV71ezc3NERgYiJCQEEybNg1yuRxBQUFYsGCBeIxmzZrB0NAQYWFhePToEXR0dGBra4vvv/9ebEA6evRoXLp0CYsXL0ZWVhZcXV0RGBhYLh4tLS1s3LgRwcHBCAsLQ1ZWFoyNjTF06FAJvqNEtYtMEAShpoMgIiIiqg24xoqIiIhIIkysiIiIiCTCxIqIiIhIIkysiIiIiCTCxIqIiIhIIkysiIiIiCTCxIqIiIhIIkysiIiIiCTCxIqIiIhIIv8HUotJ18qSlmYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJxbdhiDkhyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words2 = []\n",
        "for i in data_second.headline.values:\n",
        "    l = []\n",
        "    for j in i.split():\n",
        "        l.extend(i.split())\n",
        "        break\n",
        "    words2.append(l)   \n",
        "for i in words:\n",
        "  words2.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V98yMcl6k6Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "548e48b4-b440-4086-bab8-ad8cc8dd630c"
      },
      "source": [
        "len(words2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnCwynEziaC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "51c2d8c1-9d1b-4d24-ff70-02b073e56518"
      },
      "source": [
        "MAXLEN = 50\n",
        "EMBEDDING_DIM = 200\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=35000)\n",
        "tokenizer.fit_on_texts(words2)\n",
        "tokenized_train = tokenizer.texts_to_sequences(words2)\n",
        "x = sequence.pad_sequences(tokenized_train, maxlen = MAXLEN)\n",
        "\n",
        "w2v_model = gensim.models.Word2Vec(sentences = words2 , size=EMBEDDING_DIM , window = 5 , min_count = 1)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "# #Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt94y5XxlYlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9a5ddbb6-8e8d-408d-8a94-876dc6d971c5"
      },
      "source": [
        "#Defining Neural Network\n",
        "model_4 = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model_4.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=MAXLEN, trainable=True))\n",
        "#LSTM \n",
        "model_4.add(Bidirectional(LSTM(units=128,recurrent_dropout = 0.4 , dropout = 0.4)))\n",
        "model_4.add(Dense(64,activation='relu'))\n",
        "model_4.add(Dense(1, activation='sigmoid'))\n",
        "model_4.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 50, 200)           7614400   \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 256)               336896    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 7,967,809\n",
            "Trainable params: 7,967,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZAXuQBXHEBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrGz__TSmbuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_sarcastic_dat = np.hstack((data_first.is_sarcastic,data_second.is_sarcastic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFXGwgNRCW8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4f98c595-1309-42a6-9b2c-5145b127e57a"
      },
      "source": [
        "is_sarcastic_dat.shape,x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55328,), (55328, 50))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFujei-l9Zr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "79f0319f-668e-4ba9-869b-23d3c262ced1"
      },
      "source": [
        "# batch_size = 128 \n",
        "# Sau khi đã tăng số chiều của x từ 20 lên 50\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, is_sarcastic_dat , test_size = 0.3 , random_state = 0) \n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "history = model_4.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 38729 samples, validate on 16599 samples\n",
            "Epoch 1/5\n",
            "38729/38729 [==============================] - 201s 5ms/step - loss: 0.6923 - acc: 0.5362 - val_loss: 0.6894 - val_acc: 0.5433\n",
            "Epoch 2/5\n",
            "38729/38729 [==============================] - 196s 5ms/step - loss: 0.6886 - acc: 0.5481 - val_loss: 0.6902 - val_acc: 0.5408\n",
            "Epoch 3/5\n",
            "38729/38729 [==============================] - 198s 5ms/step - loss: 0.6616 - acc: 0.6052 - val_loss: 0.7248 - val_acc: 0.5247\n",
            "Epoch 4/5\n",
            "38729/38729 [==============================] - 201s 5ms/step - loss: 0.6233 - acc: 0.6432 - val_loss: 0.7900 - val_acc: 0.5126\n",
            "Epoch 5/5\n",
            "38729/38729 [==============================] - 197s 5ms/step - loss: 0.5679 - acc: 0.6952 - val_loss: 0.8603 - val_acc: 0.5153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnYrQDr2mYNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "outputId": "4c892fe3-be8c-4e29-c0b5-fa55d8d72e58"
      },
      "source": [
        "#Defining Neural Network\n",
        "model_5 = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model_5.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=MAXLEN, trainable=True))\n",
        "#LSTM \n",
        "model_5.add(Bidirectional(LSTM(units=128,recurrent_dropout = 0.3 , dropout = 0.5 ,return_sequences = True)))\n",
        "model_5.add(GlobalMaxPool1D())\n",
        "model_5.add(Dense(64,activation='relu'))\n",
        "model_5.add(Dense(32,activation='relu'))\n",
        "model_5.add(Dense(1, activation='sigmoid'))\n",
        "model_5.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_5.summary()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, is_sarcastic_dat , test_size = 0.2 , random_state = 0) \n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "history = model_5.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 50, 200)           7614400   \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 50, 256)           336896    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 7,969,857\n",
            "Trainable params: 7,969,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44262 samples, validate on 11066 samples\n",
            "Epoch 1/5\n",
            "44262/44262 [==============================] - 225s 5ms/step - loss: 0.6910 - acc: 0.5398 - val_loss: 0.6891 - val_acc: 0.5451\n",
            "Epoch 2/5\n",
            "44262/44262 [==============================] - 221s 5ms/step - loss: 0.6807 - acc: 0.5652 - val_loss: 0.6939 - val_acc: 0.5354\n",
            "Epoch 3/5\n",
            "44262/44262 [==============================] - 226s 5ms/step - loss: 0.6138 - acc: 0.6539 - val_loss: 0.7786 - val_acc: 0.5246\n",
            "Epoch 4/5\n",
            "44262/44262 [==============================] - 221s 5ms/step - loss: 0.5347 - acc: 0.7011 - val_loss: 1.1937 - val_acc: 0.5043\n",
            "Epoch 5/5\n",
            "15744/44262 [=========>....................] - ETA: 2:16 - loss: 0.4615 - acc: 0.7356"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-5983e9a64346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drLNer8en6Z8",
        "colab_type": "text"
      },
      "source": [
        "WORD2VEC là một trong những kĩ thuật WORDEMBEDDING nghĩa rằng nó tìm mối quan hệ về mặt ngữ nghĩa (text semantic) theo một độ đo nào đó sẽ được trình bày sau:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NYvN-TIo1N8",
        "colab_type": "text"
      },
      "source": [
        "- Ví dụ cặp từ Queen và King sẽ có mối quan hệ gần nhau hơn cặp từ Boy và Girl hay 2 địa danh chẳng hạn : Paris-Hanoi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5F_gCMhpgwp",
        "colab_type": "text"
      },
      "source": [
        "Phương pháp này tối ưu hơn One-hot Encoding ở chỗ: One-hot Encoding chỉ có nước cháy nhà-cháy cpu vì chiều của vector encoding đó cực lớn khi đang xét về ngữ cảnh là 1 văn bản."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW4lTsczn98V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Không cho vậy thì ta đọc theo dòng !!\n",
        "data_first = pd.read_json(\"Sarcasm_Headlines_Dataset.json\",lines=True)\n",
        "data_second = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\",lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7S4mIwHHWnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_first.drop(columns=\"article_link\",inplace = True)\n",
        "data_second.drop(columns=\"article_link\",inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABT4kN4dHdJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "16f5f182-57b0-4818-b4ac-329eb933ee36"
      },
      "source": [
        "data_first.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWg3rkezHoBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "dd9bf155-f100-427e-e744-605736663e9c"
      },
      "source": [
        "data_second.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic                                           headline\n",
              "0             1  thirtysomething scientists unveil doomsday clo...\n",
              "1             0  dem rep. totally nails why congress is falling...\n",
              "2             0  eat your veggies: 9 deliciously different recipes\n",
              "3             1  inclement weather prevents liar from getting t...\n",
              "4             1  mother comes pretty close to using word 'strea..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJYyrBHfHptL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat((data_first,data_second))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeepkBZhHvVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['headline']=df['headline'].apply(denoise_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_GhyTMFyGew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for i in df.headline.values:\n",
        "    l = []\n",
        "    for j in i.split():\n",
        "        l.extend(i.split())\n",
        "        break\n",
        "    words.append(l)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1bl8DpH6Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 100\n",
        "embedding_size = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(words)\n",
        "X = tokenizer.texts_to_sequences(words)\n",
        "X = pad_sequences(X, maxlen = maxlen)\n",
        "y = df['is_sarcastic']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj1_qDYNwf3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQrHxFC5IK-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MAXLEN = 50\n",
        "# EMBEDDING_DIM = 200\n",
        "\n",
        "# tokenizer = text.Tokenizer(num_words=35000)\n",
        "# tokenizer.fit_on_texts(words2)\n",
        "# tokenized_train = tokenizer.texts_to_sequences(words2)\n",
        "# x = sequence.pad_sequences(tokenized_train, maxlen = MAXLEN)\n",
        "\n",
        "w2v_model = Word2Vec(sentences = words , size=EMBEDDING_DIM , window = 5 , min_count = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD4sGtB6y2hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fcbb6fc8-68a5-439f-8c12-727ce93f1728"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtJ2qGMrynJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "003409dd-4001-4653-a3ba-c1e506842104"
      },
      "source": [
        "# #Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdUACk_BIAjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "36714a73-f63d-48e8-c68b-c253a57b919f"
      },
      "source": [
        "#Defining Neural Network\n",
        "model_5 = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model_5.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=True))\n",
        "#LSTM \n",
        "model_5.add(Bidirectional(LSTM(units=128,recurrent_dropout = 0.3 , dropout = 0.5 ,return_sequences = True)))\n",
        "model_5.add(GlobalMaxPool1D())\n",
        "model_5.add(Dense(64,activation='relu'))\n",
        "model_5.add(Dense(32,activation='relu'))\n",
        "model_5.add(Dense(1, activation='sigmoid'))\n",
        "model_5.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_5.summary()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y , test_size = 0.2 , random_state = 0) \n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "history = model_5.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 100, 200)          7614400   \n",
            "_________________________________________________________________\n",
            "bidirectional_24 (Bidirectio (None, 100, 256)          336896    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 7,969,857\n",
            "Trainable params: 7,969,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44262 samples, validate on 11066 samples\n",
            "Epoch 1/5\n",
            " 2048/44262 [>.............................] - ETA: 6:40 - loss: 0.7080 - acc: 0.5483"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-299-faac0caa9fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_G1XhOyZKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "6fa64df7-7f23-41b3-e11e-cee98b687d2b"
      },
      "source": [
        "#Defining Neural Network\n",
        "model_6 = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model_6.add(Embedding(input_dim = vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=100, trainable=True))\n",
        "#LSTM \n",
        "model_6.add(Bidirectional(LSTM(units=128,recurrent_dropout = 0.3 , dropout = 0.5 ,return_sequences = True)))\n",
        "model_6.add(GlobalMaxPool1D())\n",
        "model_6.add(Dense(64,activation='relu'))\n",
        "model_6.add(Dense(32,activation='relu'))\n",
        "model_6.add(Dense(1, activation='sigmoid'))\n",
        "model_6.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_6.summary()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y , test_size = 0.2 , random_state = 0) \n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "history = model_6.fit(x_train, y_train, batch_size = BATCH_SIZE , validation_data = (x_test,y_test) , epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 100, 200)          7614400   \n",
            "_________________________________________________________________\n",
            "bidirectional_29 (Bidirectio (None, 100, 256)          336896    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_11 (Glo (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 7,969,857\n",
            "Trainable params: 7,969,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44262 samples, validate on 11066 samples\n",
            "Epoch 1/5\n",
            "44262/44262 [==============================] - 410s 9ms/step - loss: 0.4081 - acc: 0.8065 - val_loss: 0.3253 - val_acc: 0.8626\n",
            "Epoch 2/5\n",
            "44262/44262 [==============================] - 409s 9ms/step - loss: 0.2046 - acc: 0.9195 - val_loss: 0.2586 - val_acc: 0.9010\n",
            "Epoch 3/5\n",
            "44262/44262 [==============================] - 407s 9ms/step - loss: 0.1187 - acc: 0.9558 - val_loss: 0.2846 - val_acc: 0.9184\n",
            "Epoch 4/5\n",
            "44262/44262 [==============================] - 412s 9ms/step - loss: 0.0868 - acc: 0.9686 - val_loss: 0.2753 - val_acc: 0.9252\n",
            "Epoch 5/5\n",
            "44262/44262 [==============================] - 414s 9ms/step - loss: 0.0648 - acc: 0.9759 - val_loss: 0.2890 - val_acc: 0.9300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eP6WARvyWtH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKVwzvkyXSC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZF8oI8ryXx3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTqf2mJKJpL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "model_6.save('/content/drive/My Drive/Sarcasm Detection/my_model6.h5')\n",
        "model_6.save_weights(\"/content/drive/My Drive/Sarcasm Detection/model_6_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hPn4qHnOjds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model_6.to_json()\n",
        "with open(\"/content/drive/My Drive/Sarcasm Detection/model_6_js.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvQB_Kn6PEgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "json_file = open(\"/content/drive/My Drive/Sarcasm Detection/model_js.json\", 'r')\n",
        "\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-hjmjMsPTgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model.load_weights(\"/content/drive/My Drive/Sarcasm Detection/model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fMh2e2xPfCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "746924b4-2013-4bb4-f0c5-98f6ef5bbf4f"
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 50, 200)           7614400   \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 50, 256)           336896    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 7,969,857\n",
            "Trainable params: 7,969,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxGmfVYiPgyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"/content/drive/My Drive/Sarcasm Detection/embedding_vectors_model_6\",embedding_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1CAz3BQTQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load\n",
        "# load array\n",
        "embedding_vectors_2 = load(\"/content/drive/My Drive/Sarcasm Detection/embedding_vectors.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PkEuqRRX7_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "cba67df2-b3d6-49ea-a40e-f7c5da332fc0"
      },
      "source": [
        "new_tittle = tokenizer.texts_to_sequences(df['headline'][0:5])\n",
        "new_tittle = pad_sequences(new_tittle, maxlen = maxlen)\n",
        "model_6.predict_classes(new_tittle)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NraKGSmQYOjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tittle = tokenizer.texts_to_sequences((\"Area Man Crawling On Ground Like Pig To Plug Macbook Power Cord Behind Desk\"\n",
        ",\"White House Toilet Doesn’t Know If It Can Handle Another 4 Years Of Trump\"))\n",
        "new_tittle = pad_sequences(new_tittle, maxlen = maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsaXsfhTZlba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "159280bb-302a-410c-f41e-0b5f3b859c2b"
      },
      "source": [
        "model_6.predict_classes(new_tittle)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC6LpocSevTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# saving\n",
        "with open('/content/drive/My Drive/Sarcasm Detection/tokenizer_model_6.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "979LdeTae7GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Sarcasm Detection/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer_2 = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82p23L4YfK9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tittle = pd.read_fwf('/content/drive/My Drive/Sarcasm Detection/headlines_h1.txt', sep=\"\\n\", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XRmuClzfBHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tittle = tokenizer_2.texts_to_sequences(new_tittle[0])\n",
        "new_tittle = pad_sequences(new_tittle, maxlen = maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZGe0URRfFRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = loaded_model.predict_classes(new_tittle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL7WBgPShocv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "e6ccf7df-b3cc-4ec2-e907-305e58b74dff"
      },
      "source": [
        "new_tittle[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0, 8228, 5812, 1058, 2503,    9,  101,\n",
              "        400, 1422,   36, 2216, 6664, 4067], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzwB2eY0h4rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnqYd-9vip3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique, counts = np.unique(pred, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr8wosoMiz_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6c55feed-4b03-42c6-daa6-01278fe08d0b"
      },
      "source": [
        "counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([389, 319])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdDfLdbKi25k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6a9da395-e481-4f43-cd2b-0745102ef72c"
      },
      "source": [
        "counts[0]/counts.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxswKc12jFbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "head_lines = [\"Entire Oklahoma State Team To Boycott Season After Mike Gundy Seen In NCAA Shirt\",\n",
        "\"Fantasy Baseball League Commissioner Knows Handling Of Pandemic Will Define His Legacy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nibFAAcGkRHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tittle = tokenizer_2.texts_to_sequences(head_lines)\n",
        "new_tittle = pad_sequences(new_tittle, maxlen = maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuf2Al0SkUFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = loaded_model.predict_classes(new_tittle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSk0wFdzkWWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6d1cd4f9-bcdd-4df8-9d9e-331170aa3c8d"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRCr-zdkXCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "64c0ff57-0354-401a-f3cd-28817fbc6787"
      },
      "source": [
        "head_lines = [\"6 Staffers Working On Trump’s Tulsa Rally Test Positive For COVID-19\",\n",
        "\"Fantasy Baseball League Commissioner Knows Handling Of Pandemic Will Define His Legacy\"\n",
        ",\"3 States See Record High In Daily Coronavirus Infections After Reopening\"\n",
        ",\"Trump Fires U.S. Attorney Who Led Probes Of The President’s Men\"\n",
        ",\"Huh, Boyfriend’s Ex Just Made Interesting Hair Choice\"]\n",
        "new_tittle = tokenizer_2.texts_to_sequences(head_lines)\n",
        "new_tittle = pad_sequences(new_tittle, maxlen = maxlen)\n",
        "pred = loaded_model.predict_classes(new_tittle)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9g3q930klmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}